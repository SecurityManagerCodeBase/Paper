\documentclass{sig-alternate}
\usepackage[T1]{fontenc}
\usepackage{array}
\usepackage{verbatim}
\usepackage{booktabs}
\usepackage{fancyvrb}
\usepackage{url}
\usepackage[english]{babel}
\usepackage{listings}
\usepackage{myref}
\usepackage{todos}

\makeatletter
\makeatother

\begin{document}

%\author{BLINDED FOR SUBMISSION}

\title{Give 'em less rope: Open Source Evidence of Java Sandbox Perversions}

\numberofauthors{1} 
\author{\alignauthor Zack Coker, Michael Maass, Tianyuan Ding, Claire Le Goues, and Joshua Sunshine \\
\affaddr{Carnegie Mellon University} \\
\email{\{zfc,mmass\}@cs.cmu.edu, tding@cmu.edu, \{clegoues,sunshine\}@cs.cmu.edu}
} 

\maketitle
%JSS: This is to force page numbers.
\thispagestyle{plain} 
\pagestyle{plain}
\begin{abstract}
The ubiquitously-installed Java Runtime Environment (JRE) executes
untrusted code inside a sandbox to protect the host machine from potential
malicious behavior. However, dozens of recent exploits have successfully
escaped the sandbox, thereby enabling attackers to infect countless
Java hosts. It is essential to distinguish patterns of malicious use
from patterns of benign use to proactively prevent future exploits.
We therefore performed an empirical study of benign open-source Java
applications and compared their use of the sandbox to the usage present
in recent exploits. We found that benign applications with secured
sandboxes do not modify the security manager, the security policy
enforcement mechanism, after it is first set and do not attempt to
directly use privileged classes. Exploits routinely do both. We derive two rules from these results to prevent (1) security manager modifications and (2) privilege escalation. We evaluated their protection merits in a case study using runtime monitors to enforce the rules during the execution of exploits and benign applications. The rules stop all ten Metasploit Java 7 exploits without breaking backwards-compatibility with benign applications. These practical rules should be enforced in the JRE to fortify the Java sandbox.
\end{abstract}

\section{Introduction}


\begin{figure}
\begin{centering}
\includegraphics[width=2in]{most_targeted_apps_ibm_xforce}
\par\end{centering}
\caption{Pie chart showing the most
targeted applications on enterprise workstations, according to to
a Dec. 2013 survey of Trusteer customers \cite{xforceQ12013}. Java
\label{fig:most-targeted-applications}represented half of all attack-attempts in their sample.}
\end{figure}

Java applications are very popular targets for malicious attackers (see
Figure~\ref{fig:most-targeted-applications}), for three broad reasons.  First,
it is the Java Runtime Environment (JRE) is widely installed on user endpoints.
Second, the JRE can (and often does) execute external code, in the form of
applets and Java Web Start (JWS)~\cite{_java_web_start}
applications~\cite{gong1997going,gong2003inside}.  Finally, Java contains
hundreds of vulnerabilities \todo{Can we add raw numbers here, say over
  2011-2013?}, including zero-day vulnerabilities (e.g. CVE-2013-0422).  In the
common scenario, often referred to as a ``drive-by download'', attackers lure
users to a website that contains a hidden malicious applet. Such malicious
applets exploit security vulnerabilities in the JRE to deliver malware,
typically leaving the user unaware.

In theory, such attacks should not be so common: 
Java provides a sandboxing mechanism that enables the safe execution of untrusted code and isolates
components another. Both the host application and host machine should
therefore be protected from malicious behavior on the part of
external code.  In practice, these security mechanisms are problematically
buggy, such that the sandbox often fails to properly contain external code. 
Java malware typically alters the sandbox's
settings~\cite{garber_2012}.  Such exploits take advantage of defects in either
the JRE's implementation the application's configuration of the sandbox to 
disable the security manager, the component of the sandbox responsible for enforcing the
security policy~\cite{fireeye_2013,svoboda_anatomy_blog_2013,security_explorations_2012,blackhat_2012}.

In this paper, we investigate this disconnect between theory and practice.  We
hypothesize that it results primarily from unecessary complexity and flexibility
in the design and engineering of Java's security mechanisms.  \todo{Can someone
  flesh this out?  What types of complexity/flexibility does the sandbox allow
  that we don't need?  Likely relevant example: the ability to change the
  security manager at runtime.} In particular, we
hypothesize that benign applications interact with the security manager in ways
that are measurably different from the ways that exploitative applications do.  
If true, this difference can be leveraged to prevent future attacks.

To validate these insights, we conducted an empirical study of benign open
source Java applications.  We sought to answer the research question: How do benign
applications interact with the Java security manager?  We identified 46
open-source Java projects that use the security manager, taken from the Qualitas
Corpus \cite{QualitasCorpus:APSEC:2010} and GitHub. For each project, we
isolated code that interacts with the security manager, manually characterized
those interactions, and constructed and used a Java Virtual Machine Tool Interface (JVMTI) agent
to confirm that our characterizations were accurate at runtime.

We discovered that there are two types of security managers used in
practice. \emph{Defenseless} security managers enforce a policy that allows code
inside the sandbox to modify sandbox settings.  Applications with defenseless
managers are inherently insecure, because externally-loaded malicious code can
modify or disable the security manager.  In our study, this situation typically
arose in applications that modified sandbox settings at runtime, often because
they use the security manager to enforce policies unrelated to security.
\todo{I think this train of thought needs one more observation, starting with
  something like ``this is interesting because''.  I'm drawing a blank on what
  should come after the ``because'', however, hence this todo.}
\emph{Self-protecting} security managers do not allow sandboxed code to modify
security settings.  The applications in our dataset with self-protecting
managers, including all applets and JWS applications, did not change those
settings over the course of execution.  It might still be possible to exploit
such applications due to defects in the JRE code that enforces security
policies, but not due to poorly-deployed local security settings.

In practice, applications that attempt to use the sandbox for its intended
purpose---protection from exploitative external code---do not make use of its
vast flexibility.  We therefore propose two runtime rules to fortify the Java
sandbox against the two most common modern attack types. We evaluate our rules
with respect to their ability to guard against the ten applets in Metasploit
4.10.0%
\footnote{http://www.metasploit.com/%
} that successfully exploit unpatched versions of Java 7. Taken together, the
monitors detected and stopped all ten exploits, and neither monitor produces
false-positives for a corpus of benign JWS applications.
We are engaged in an
on-going discussion on the security-dev mailing list for OpenJDK about
implementing runtime enforcement of these rules in the JVM itself.

The contributions of this papers are as follows:
\todo{CLG would like us to rethink these contributions once the rest of the paper
  has been modified.}
\begin{itemize}
\item An analysis of privilege escalation in the Java security model and
recent Java exploits (Section \ref{sub:Java-Exploits}).
\item An empirical study of Java sandbox usage in benign, open-source applications
(Sections \ref{sec:Security-Manager-Study} and \ref{sec:Study-results}).
\item Two novel rules for distinguishing between benign and malicious Java
programs (Section \ref{sec:Rules-for-Fortifying}).
\item A case study evaluation of the protection merits of our rules with a discussion of practical implementation considerations (Section \ref{sec:Mitigations}).
\end{itemize}

\section{Background}\label{sec:Background}

In this section, we describe the Java sandbox
(Section~\ref{sec:sandbox}), distinguish between defenseless and self-protecting
Security Managers (Section~\ref{sec:secmanagers}) and provide a high-level
description on how exploits commonly bypass these security mechanisms
(Section~\ref{sec:Java-Exploits}). 

\subsection{The Java sandbox}
\label{sec:sandbox}

\begin{figure}
\includegraphics[width=\columnwidth]{sandbox_overview}
\caption{High-level summary of the components of the Java 
\label{fig:Sandbox-high-level-summary}
sandbox.}
\end{figure}

The Java sandbox is designed to safely execute code from untrusted
sources. 
The relevant components are summarized in Figure
\ref{fig:Sandbox-high-level-summary}. 
When a \textit{class loader} loads a class (e.g., from
the network, filesystem, etc.), it assigns the class a \textit{code source} that
indicates the code origin, and associates it with a \textit{protection
  domain}. Protection domains segment the classes into groups by
\textit{permission set}. These sets
contain permissions that explicitly allow actions with security
implications, such as writing to the filesystem, accessing the network, using
certain reflection features, etc (see a more complete list
at~\cite{_permissions_2014}).  Unlisted actions are disallowed for classes in
that protection domain.  \emph{Policies}, written in the Java policy
language~\cite{_java_policy_language}, define the permission sets and the code
sources associated with them. 
By default, classes loaded from the local file system are run
without a sandbox; all other applications are run inside a restrictive
sandbox.  This prevents applications from the network or other untrusted sources
from executing malicious operations on the host system.

The sandbox is activated by setting a \emph{security manager}, which acts as the
gateway between the sandbox and the rest of the application. Whenever a
sandboxed class attempts to execute a method with security implications, that
method queries the security manager to determine if the operation should be
permitted.  We refer to such methods as \emph{privileged code}.  For example, if
a sandboxed application attempts to write to a file by using
\texttt{java.io.FileOutputStream}, the latter will first
check with the security manager to ensure that a write to that file is
permitted.  Missing checks in code that \emph{should} be protected are a common
source of Java vulnerabilities, because the security-critical code must initiate
the check.  Note that such vulnerabilities lie in the JVM itself (i.e., the code
written by the Java developers), not in the code that uses the sandbox to
execute untrusted external applications.

To perform a permission check, the security manager walks the call stack to
ensure each class in the current stack frame has the permissions necessary to
perform the action.  Consider a sandboxed class \texttt{Sandboxed} that attempts
to create a \texttt{java.io.FileOutputStream}. The \texttt{FileOutputStream}
constructor checks with the security manager to determine whether
\texttt{Sandboxed} has permission to open the file in question.  The manager
then checks the permission sets of each class in the call stack:
\texttt{FileOutputStream}, and then \texttt{Sandboxed}.  If the permission check
reaches a class in the stack frame that does not have the correct permissions,
the security manager will throw a \texttt{SecurityException}.  Privileged code,
such as \texttt{FileOutputStream} in our example, can wrap sensitive actions in
a \texttt{doPrivileged} call to preempt the stack check.  This allows privileged
code sections to perform actions with security implications at the request of
non-privileged code.\footnote{Stack-based access control is discussed in more
  detail
  in~\cite{banerjee_stack-based_2005,besson_stack_2004,d._s._wallach_understanding_1998,erlingsson_irm_2000,fournet_stack_2002,pistoia_beyond_2007,zhao_type_2005}.}

\subsection{Defenseless vs. self-protecting managers}
\label{sec:secmanagers}

\begin{table*}
\caption{List of sandbox-defeating permissions. A security manager that enforces
a policy containing any of these permission is sufficient to result
\label{tab:defenseless-permissions}
in a defenseless sandbox.}


\centering{}%
\begin{tabular}{ll}
\toprule 
\textbf{Permission} & \textbf{Risk}\tabularnewline
\midrule
RuntimePermission(``createClassLoader'') & Load classes into any protection domain\tabularnewline
RuntimePermission(``accessClassInPackage.sun'') & Access powerful restricted-access internal classes\tabularnewline
RuntimePermission(``setSecurityManager'') & Change the application's current security manager\tabularnewline
ReflectPermission(``suppressAccessChecks'') & Allow access to all class fields and methods as if they are public\tabularnewline
FilePermission(``<\textcompwordmark{}<ALL FILES>\textcompwordmark{}>'',
``write, execute'') & Write to or execute any file\tabularnewline
SecurityPermission(``setPolicy'') & Modify the application's permissions at will\tabularnewline
SecurityPermission(``setProperty.package.access'') & Make privileged internal classes accessible\tabularnewline
\bottomrule
\end{tabular}
\end{table*}

\todo{I think we need to hammer this point a bit more: Java's security model is
  too complicated---meaning it's implemented badly/in a way that's full of
  bugs---and also unecessarily so---because people don't need all that
  flexibility.  I'm not sure how to expand this text to help with that
  point-hammering, but I think it would be useful to the development of the
  argument.  Anyone see what I'm getting at and want to try to expand accordingly?}
 Java is flexible about when in an application's execution the sandbox
is configured and enabled. The default case for web applets and applications
that use Java Web Start is to set what we call a \textit{self-protecting} security
manager before loading the application from the network. The security
manager, and thus the sandbox, is self-protecting in the sense that
it does not allow the application to change sandbox settings. We contrast
self-protecting managers with those we call 
\textit{defenseless}, meaning that sandboxed applications have privileges that
permit them to modify or disable the security manager at runtime.  Such a
security manager is the exact opposite
of self-protecting. A defenseless manager is virtually useless in terms of improve the
security of either a constrained application or its host. However, we find
in Section~\ref{sec:Study-results} that the developers of some benign applications
have found interesting non-security uses for defenseless managers. 

Table~\ref{tab:defenseless-permissions} summarizes the set of permissions
used to distinguish between self-protecting and defenseless security
managers. We consider any security manager that enforces a policy
that contains any one of the listed permissions to be defenseless.
A subset of the permissions in this list were identified in \cite{security_explorations_2012}. 


\subsection{Exploiting Java Code}
 \label{sec:Java-Exploits}

\iffalse
\begin{figure}
\begin{centering}
\begin{lstlisting}[language=Java,basicstyle={\scriptsize}]
import java.lang.reflect.Method; 
import java.security.AccessController; 
import java.security.PrivilegedExceptionAction;   

public class Payload 
        implements PrivilegedExceptionAction {         
    public Payload() {
        try {
            AccessController.doPrivileged(this);
        } catch(Exception exception) { }     
    }

    public void run() {
        // Disable sandbox
        System.setSecurityManager(null);
    }

    public static void outSandbox() {
        // Do malicious operations
    }
}
\end{lstlisting}

\par\end{centering}

\caption{A typical sandbox-disabling  \label{fig:A-typical-exploit-payload}
Java exploit payload from http://pastebin.com/QWU1rqjf.}
% CLG isn't convinced that this figure is adding enough to justify the amount of
% space it's taking up.
\end{figure}
\fi

% Between 2011 and 2013, drive-by 
% downloads that used Java applets as the vector were widely reported.\todo{needs
%   a reference.  Also, I'm considering killing this sentence, but haven't decided
% yet.}
%
% This section provides an analysis of privilege escalation in the Java
% security model and recent Java exploits. 
While the Java sandbox \textit{should} prevent malicious applets from
executing their payloads, defects in the
Java Runtime Environment (JRE) enforcement of these security mechanisms permit
malicious code to set a security manager to \texttt{null}.  
Setting the security manager to \texttt{null} disables the sandbox, allowing
previously constrained classes to perform operations with the privileges of 
the JRE itself. 
This approach was taken in a large proportion of drive-by downloads exploiting
Java applets between 2011 and 2013~\cite{fixme-metasploit}. 
%Figure \ref{fig:A-typical-exploit-payload}
%shows a typical payload class whose privileges have been elevated
%by an exploit to allow it to disable the sandbox. This example payload
%uses \texttt{doPrivileged} to allow the unprivileged exploit class
%to execute the operations in the payload without causing a \texttt{SecurityException}.
%
There are a couple of methods by which an exploit may nullify a security manager:

\noindent\textbf{Type confusion.} An attacker breaks type
safety to craft an object that can perform operations as if it had
a different type. Commonly, attackers craft objects that either
(1) point to the \texttt{System} class or (2) act as if they had
the same type as a privileged class loader (see CVE-2012-0507 \cite{_vulnerability_2012_0507}).
In the first case, any operation performed on the
masqueraded class is applied to the real \texttt{System} class, allowing
the attacker to directly alter the field storing the security manager. 
In the second case, the malicious class can load an exploitative
payload with elevated privileges.

\noindent\textbf{Confused deputy.} Exploitative code ``convinces'' another
class to return a reference to a privileged class~\cite{hardy_confused_1988}
known to contain a vulnerability (such as a missing security check).  The
attacker then takes advantage of that vulnerability to disable the sandbox 
(see CVE-2012-4681 \cite{_vulnerability_2012_4681}).
The ``convincing'' is necessary
because it is rare that a vulnerable privilege class is directly accessible
to all Java applications; doing so violates the \textit{access
control} principle that is part of the Java development culture.%
\footnote{\url{https://blogs.oracle.com/jrose/entry/the_isthmus_in_the_vm}%
} Once an exploit gains access to a vulnerable privileged class, that
class can be ``tricked'' into executing code that disables the sandbox

The confused deputy attack is an example of privilege escalation.  Most
privileged classes in the JRE implement features that can be accessed via
less-privileged code paths; benign applications therefore rarely need to
directly access them. 
%
%  For example, the \texttt{sun.reflect} package implements
% reflection operations; it also has all permissions. However, Java applications
% do not have direct access to the \texttt{sun} classes with default JRE
% configurations; instead, they are expected to use classes in the
% \texttt{java.lang.reflect} package to use reflection.  The \texttt{java} package
% classes do not perform privileged operations, but do have access to the
% privileged classes in the \texttt{sun} package.
Because a privileged class loader must be used to load a privileged class, 
a non-privileged class does not typically have access to vulnerable
privileged classes anyway. The danger of vulnerabilities in privileged
classes is therefore mitigated, because such vulnerabilites cannot be exploited
directly unless malicious code succeeds in modifying its privileges first. 
This redundancy is implicit in the Java security model: If any class
could load more privileged classes and directly cause the execution
of privileged operations, the sandbox in its current form would serve
little purpose. In sections \ref{sec:Rules-for-Fortifying} and \ref{sec:Mitigations}
we discuss how we can leverage these distinctions to further fortify
the sandbox.

% In the rest of this paper, we do not concern ourselves with the specifics of
% particular exploits. We will now explore how benign applications interact with
% the sandbox to define ways of delineating them from exploits.


\section{Security Manager Study}\label{sec:Security-Manager-Study}

The Java security model is complex
The nature of recent Java exploits caused us to ask the question: Do applications need access to any facility for disabling or weakening the sandbox? This study aims to answer this question and provide data in support of JVM enhancements to fortify the Java sandbox.
We focus our efforts on the security manager, as it is the means by
which applications interact with the sandbox. 

Any JVM enhancements that are to stop even zero-day exploits while maintaining backwards-compatibility with benign applications must be designed with an understanding of which operations both exploitive
and benign applications perform on the security manager. Assuming
there is a difference between the set of operations performed by exploits
and those performed by benign applications, one can exclude the operations
on which exploits depend, that are not of use to benign applications. This strategy would help ensure the sandbox
continues to enforce its policy in a given execution without having
to deal with the wide diversity in the manifestations of vulnerabilities
within the JRE or the subtleties of their exploits. In this section
we describe the methodology for and limitations of an empirical study
that validated this strategy and answers our motivating question.


\subsection{Dataset}\label{sec:Applications-Studied}

\begin{table}
\caption{Table of applications included in the security manager study.}
\label{Table:applications-studied}


\centering{}%
\begin{tabular}{lll}
\toprule 
Application Name & Description & Repo\tabularnewline
\midrule
(Apache) Ant & Java Project Builder & QC\tabularnewline
(Apache) Batik & SVG Image Toolkit & QC\tabularnewline
C-JDBC & DB Cluster Middleware & QC\tabularnewline
Compiere & Business Tools & QC\tabularnewline
(Apache) Derby & Relational Database & QC\tabularnewline
DrJava & IDE & QC\tabularnewline
Eclipse  & IDE & QC\tabularnewline
FreeMind & Mind-Mapping Tool & QC\tabularnewline
Galleon & Media Server & QC\tabularnewline
(Apache) Hadoop & Distrib. Comp. Frwk. & QC\tabularnewline
Hibernate & Obj.-Rel. Mapper & QC\tabularnewline
HyperSQL & SQL DB & QC\tabularnewline
JBoss & Application Middleware & QC\tabularnewline
JRuby & Ruby Interpreter & QC\tabularnewline
(Apache) Lucene & Search Software & QC\tabularnewline
(Apache) MyFaces & Server Software & QC\tabularnewline
NekoHTML & HTML Parser & QC\tabularnewline
Netbeans & IDE & QC\tabularnewline
OpenJMS & Messaging Service & QC\tabularnewline
Quartz  & Job Scheduler & QC\tabularnewline
QuickServer & TCP Server Frwk. & QC\tabularnewline
Spring Framework & Web Dev. Library & QC\tabularnewline
(Apache) Struts & Web Dev. Library & QC\tabularnewline
(Apache) Tapestry & Web Dev. Library & QC\tabularnewline
(Apache) Tomcat & Web Server & QC\tabularnewline
Vuze & File Sharing App. & QC\tabularnewline
Weka & Machine Learning Algs. & QC\tabularnewline
(Apache) Xalan & XML Trans. Library & QC\tabularnewline
(Apache) Xerces & XML Parsing Library & QC\tabularnewline
AspectJ & Java Extension & Github\tabularnewline
DemoPermissions & Spring Extension & Github\tabularnewline
driveddoc & Application Connector & Github\tabularnewline
FileManager- & FTP Server & Github \\ FtpHttpServer\tabularnewline
Gjman & Development Toolkit & Github\tabularnewline
IntelliJ IDEA & IDE & Github\tabularnewline
Jmin & Lightweight JDK & Github\tabularnewline
MCVersion-Control & Minecraft Utility & Github\tabularnewline
NGOMS & Business Tools & Github\tabularnewline
oxygen-libcore & Android Dev. Lib. & Github\tabularnewline
refact4j & Meta-model Prog. Frwk. & Github\tabularnewline
Security-Manager & Alt. Security Manager & Github\tabularnewline
Spring-Modules & Spring Extension & Github\tabularnewline
System Rules & JUnit Extension & Github\tabularnewline
TimeLag & Sound Application & Github\tabularnewline
TracEE & JavaEE Support Tool & Github\tabularnewline
Visor & Closure Library & Github\tabularnewline
\bottomrule
\end{tabular}
\end{table}


Our empirical analysis used applications from the Qualitas Corpus
(QC) \cite{QualitasCorpus:APSEC:2010} and GitHub to form a dataset
of applications that use the security manager. To filter relevant
applications out of the 112 applications in QC, we performed a simple
\texttt{grep} of each application's source code to find instances
of the keyword \textit{SecurityManager}. When any instance of the
keyword was found, we included the application in our dataset. This
filtering reduced the set of applications to inspect from 112 to 29. 

We performed a similar process on GitHub while searching only Java files. The keyword \textit{System.setSecurityManager(} was added to remove false positives. To include applications that disable the manager we also searched for \textit{System.setSecurityManager(null)}. We picked the top seven applications from the results for each keyword, removed false positives, and ended up with an additional 17 applications that were not already in QC. We only looked at the latest commit.


The Qualitas Corpus is a curated collection of open source Java applications
for use in reproducible software studies. We investigated sandbox
interactions in 29 applications from QC version 20130901.


While QC provides a strong starting point for the construction of
a dataset for this study, their inclusion criteria%
\footnote{http://qualitascorpus.com/docs/criteria.html%
} leads to the inclusion of large, popular applications and frameworks.
We diversified our dataset by turning to GitHub. Table \ref{Table:applications-studied}
lists all studied applications. Version numbers and Git commit hashes
are available in an online supplement.%
\footnote{http://goo.gl/dtcqTM%
}

\subsection{Methodology}

As discussed in the previous sections, it is widely known within the
Java security community that current exploits that operate on the
security manager perform one operation: They disable it. To understand
the operations benign applications perform on the manager, we undertook
an empirical analysis consisting of static, dynamic, and manual inspections
of the open source Java application landscape. More precisely, we
answer the following research question: How do open source Java applications
interact with the security manager? To answer this question, our empirical
analysis aimed to validate four independent hypotheses. Each hypothesis
is paired with a mitigation that can be implemented if the hypothesis
is supported. The mitigations are given names that denote their relative
strengths when compared to each other. For example, a ``weak'' mitigation
stops a small number of in-scope exploits and is easily bypassed.
An ``ideal'' mitigation stops all in-scope exploits and can never
be bypassed. Our hypotheses and their accompanying mitigations follow: 

\textbf{Hypothesis 1:} \emph{Benign applications do not disable
the security manager.} If this hypothesis holds, exploits can be differentiated
from benign applications by any attempt to disable the current security
manager. This \textbf{weak mitigation} would be easy to implement,
but exploits that weaken the sandbox without disabling it would remain
a threat. For example, attackers could potentially bypass the mitigation
by modifying the enforced policy to allow the permissions they need
or they could replace the current manager with one that never throws
a \texttt{SecurityException}.

\textbf{Hypothesis 2:} \emph{Benign applications do not weaken the
security manager}. Validation of this hypothesis would enable
mitigations that prevent attackers from weakening or disabling the
sandbox. However, an implementation of this \textbf{moderate mitigation}
would require differentiating between changes which weaken the sandbox
and those that do not. Classifying changes in this manner autonomously is difficult
because it requires context specific information that a general mitigation
strategy may not have. For example, if a permission to write to a
file is replaced by a permission to write to a different file, is
the sandbox weakened, strengthened, or exactly as secure as it was
before?

\textbf{Hypothesis 3:} \emph{Benign applications do not change the
sandbox if a self-protecting security manager has been set}. If supported,
it is possible to implement a mitigation strategy that disallows any
change to a security manager that is enforcing a strict policy (as
defined in Section \ref{sec:Background}). To implement this \textbf{strong
mitigation}, a runtime monitor must determine if a security manager
is self-protecting at the time the manager is set. This can be easily
achieved. While this mitigation has the same outcome as the moderate
mitigation, it is significantly easier to implement soundly and it
is therefore more likely to be effective in practice. 

\textbf{Hypothesis 4:} \textit{Benign applications do not change a
set security manager.} If the study supports this hypothesis, any
attempted change to an already established security manager can be
considered malicious. The \textbf{ideal mitigation} could easily be
implemented in the JVM. 

With the dataset in hand, we created static and dynamic analysis tools
to assist in the manual inspection of each application. Our static
analysis tool is a FindBugs \cite{hovemeyer_finding_2004} plugin
that uses a dataflow analysis to determine where \texttt{System.setSecurityManager}()
is called, as well as the lines of code where its arguments were initialized.
We created a dynamic analysis tool using the Java Virtual Machine
Tool Interface (JVMTI) \cite{_jvmti}. JVMTI is designed to allow
tools to inspect the current state of Java applications and control
their execution; it is commonly used to create Java debugging and
profiling tools. Our dynamic analysis tool set a modification watch
on the \texttt{security} field of Java's \texttt{System} class. This
field holds the current security manager object for the application.
The watch prints out the class name, source file name, and line of
code where any change to the field took place. A special notice is
printed when the field is set to \texttt{null}. 

We split the dataset between two reviewers. The reviewers both analyzed
applications using the following steps:

\begin{enumerate}
\item Run grep on all Java source files in the application
to output every line containing the keyword \textsl{SecurityManager} and the 5 lines before and after it.
\item Reject any application where it is clear from the grep output that the keyword is used in ways that are unrelated to the security manager class.
\item Run the static analysis on retained applications. 
\item Manually inspect code identified in step 3.
Start where the manager is set and trace 
back to locations where potential security
managers are initialized. 
\item Manually inspect all of the lines returned in step 1, looking for how the application interacts with
the sandbox. 
\item Execute the application with the dynamic analysis using parameters
and actions steps 4 and 5 show affect the security
manager to verify conclusions from previous steps.
\item Summarize the operations performed
on the security manager with an emphasis on points that support or
reject each hypothesis.
\end{enumerate}

We undertook a pilot study where each reviewer
independently inspected the same six applications and compared their
results. This ensured reviewers understood the analysis steps and produced
consistent results.


\section{Study Results}\label{sec:Study-results}

\begin{table}
\caption{Classification of application interactions with the security manager.}
\label{tab:Classification-of-Application}

\centering{}%
\begin{tabular}{lrrr}
\toprule 
Type of Interaction & QC & GitHub & Total\tabularnewline
\midrule
1. Sets manager, nothing else & 6 & 1 & 7\tabularnewline
2. Changes set security manager & 5 & 3 & 8\tabularnewline
3. Support being sandboxed & 10 & 3 & 13\tabularnewline
4. Interactions only in unit tests & 3 & 5 & 8\tabularnewline
5. No interactions (false positive) & 5 & 5 & 10\tabularnewline
\bottomrule
\end{tabular}
\end{table}



We characterized the security manager interactions of the applications in our dataset by assigning each one of five types. The
types are summarized as follows: (1) applications that set a
security manager that does not get changed later in the application's
execution, (2) applications that change a set manager at some point
in the program's execution, (3) applications that interact with a
security manager in production code if one is set but do not modify the manager or its policy, (4) applications
that only interact with the manager in unit tests, and (5) applications that do not actually interact with the manager. Table \ref{tab:Classification-of-Application}
summarizes our dataset using these types.

Type 3, 4, and 5 applications will not be discussed further because their interactions with the sandbox cannot violate our hypotheses.

Type 2 applications can violate our hypotheses and therefore provide the bulk of our discussion below. However, a few Type 1 applications are discussed due to the novel insights they provide into benign interactions with the sandbox. We discuss application that use the sandbox for purposes that are not security related in Section \ref{sub:Non-security-uses-of}
and applications that use the sandbox for its intended security purposes in Section \ref{sub:Using-the-Security}.

\subsection{Evaluation of the Hypotheses}\label{sub:Evaluation-of-the-hypotheses}

We only require one counterexample to falsify a hypothesis from Section
\ref{sec:Security-Manager-Study}. This section summarizes how our
hypotheses held up against the results of this study.

\textbf{Hypothesis 1}: \emph{Benign applications do not disable
the security manager.} The investigation determined
that some benign applications do disable the security manager, but these were typically were not using the sandbox for security purposes.

\textbf{Hypothesis 2}: \emph{Benign applications do not weaken the
security manager.} Several applications provided methods for the user to dynamically change the security policy or the manager in ways that can reduce the security of the sandbox.

\textbf{Hypothesis 3}: \emph{Benign applications do not change the
security manager if a self-protecting security manager has been set}.
This hypothesis was supported by both datasets.

\textbf{Hypothesis 4}: \emph{Benign applications do not change a
set security manager.} This hypothesis was falsified by multiple applications that changed the security manager.

In short, the strong mitigation is the only proposed mitigation that
can be implemented without breaking benign applications.

\subsection{Non-security uses of the Sandbox}\label{sub:Non-security-uses-of}

This section describes applications that provide novel insights into benign sandbox interactions unrelated to satisfy security
requirements. Most of these applications used the
sandbox to enforce architectural constraints when interacting with
other applications or forcibly disabled the sandbox to reduce development
complexity.

\subsubsection{Enforcing Architectural Constraints}

Java applications often call \texttt{System.exit()} when a non-recoverable
error occurs. This error handling strategy causes problems when applications that use it are used as libraries. When the library application executes \texttt{System.exit()},
the calling application is closed as well because both applications
are running in the same JVM. This is not the desired
outcome in several cases. 

To prevent this outcome without modifying the library application,
the calling application needs to enforce the architectural constraint
that libraries can not terminate the JVM. In practice, applications
enforce this constraint by setting a security manager
that prevents \texttt{System.exit()} calls.

This case appears in Eclipse, which uses Ant as a library. When an
unrecoverable error condition occurs, Ant kills the JVM to terminate
execution of the build script currently running. However, Eclipse
should continue executing and report an error to the user when Ant
terminates with an error code. Figure \ref{fig:Eclipse-snippet} shows
how Eclipse sets a security manager to enforce this constraint right
before Ant is executed. After Ant closes and any error conditions
are handled, the original manager is restored.

\begin{figure}
\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=691,xrightmargin={0.1cm},numbersep={-10pt}]
    System.setSecurityManager(new AntSecurityManager(originalSM, Thread.currentThread()));
    ...
\end{lstlisting}


\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=703,xrightmargin={0.1cm},numbersep={-10pt}]
    getCurrentProject().executeTargets(targets); \\Note: Ant is executed on this line
    ...
\end{lstlisting}


\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=721,xrightmargin={0.1cm},numbersep={-10pt}]
    finally {
    ...
\end{lstlisting}


\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=725,xrightmargin={0.1cm},numbersep={-10pt}]
        if (System.getSecurityManager() instanceof AntSecurityManager) { 
            System.setSecurityManager(originalSM); 
        }
\end{lstlisting}


\protect\caption{Snippet of Eclipse code that uses a security manager to prevent Ant
from terminating the JVM when Ant encounters an unrecoverable error.}\label{fig:Eclipse-snippet}
\end{figure}

GJMan also enforces this constraint and contains a code comment referencing a
blog post that we believe is the origin of this solution.\footnote{http://www.jroller.com/ethdsy/entry/disabling\_system\_exit} 

In total, we found 3 applications that use a variation of this technique:
Eclipse, GJMan, and AspectJ. While this technique does enforce the
desired constraint, and appears to be the best solution available
in Java at the moment, it may cause problems when applications are
also using the sandbox for security purposes. The technique requires
the application to dynamically change the security manager, which requires either a defenseless manager or for the application
to be carefully written to prevent malicious code from weakening the sandbox. Defenseless security managers
are not capable of reliably enforcing a serious security policy.

\subsubsection{Reducing Web Application Development Complexity}\label{sub:Reducing-Web-Application-Complexity}

We found applications that were complicated by the Java security policies
for web applications (applets and applications launched via JWS). By default, Java executes such an application inside a restrictive
sandbox that severely limits the operations the application can perform,
excluding operations such as accessing local files, retrieving resources
from any third party server, or changing the security manager. 

Applications in our set that cannot run in a restrictive sandbox universally opted to run outside of the sandbox because the alternative is to painstakingly construct the application to run reasonably without required privileges (e.g. by detecting the sandbox and disabling privileged operations). To avoid executing the applet in a restrictive
sandbox, a developer must get the application digitally signed
by a recognized certificate authority then specify that the application should
run outside of the sandbox. We found that applications using this method attempted
to set the security manager to \texttt{null} at the beginning of the
application, causing a restrictive sandbox to catch the security violation and
terminate the application.

We found two applications that do this: Eclipse and
Timelag. The rationale for disabling the manager in Eclipse is explained in a code comment that reads, "The launcher to start eclipse using webstart. To use this launcher, the client must accept to give all security permissions." Timelag performs the same operation but does not contain any comments, thus we can only infer their motivation.

\subsection{Using the Security Manager for Security Purposes}\label{sub:Using-the-Security}

This section describes applications that provide novel insights into benign sandbox interactions related to improving the security
posture of the application. Several of these applications clearly violate hypotheses 1, 2, and 4: Batik, Eclipse, and Spring-modules provide
methods that allow the user to set and change an existing manager,
and Ant, Freemind, and Netbeans explicitly set then change the manager.

\begin{figure}
\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=156,xrightmargin={0.1cm},numbersep={-10pt}]
    public void enforceSecurity(boolean enforce){ 
    SecurityManager sm = System.getSecurityManager();

    if (sm != null && sm != lastSecurityManagerInstalled){
        ...
\end{lstlisting}


\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=163,xrightmargin={0.1cm},numbersep={-10pt}]
        throw new SecurityException
            (Messages.getString(EXCEPTION_ALIEN_SECURITY_MANAGER));   
    }                  
    if (enforce) { 
        ...
\end{lstlisting}


\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=173,xrightmargin={0.1cm},numbersep={-10pt}]
        installSecurityManager();         
    } else {             
        if (sm != null) {                 
           System.setSecurityManager(null);
           lastSecurityManagerInstalled = null;             
           ...
\end{lstlisting}


\protect\caption{Security manager interactions in Batik.}\label{fig:Batik-snippet}
\end{figure}


Figure \ref{fig:Batik-snippet} shows an interesting case from Batik
copied from \texttt{ApplicationSecurityEnforcer.java}. This method
allows users to optionally constrain the execution of an an application
that uses the Batik SVG Toolkit. It takes a parameter that acts as
a switch to turn the sandbox on or off. The download page on the Batik
website shows several examples of how to use the library. Two set
a security manager at start up: the squiggle browser demo and the
rasterizer demo. While the squiggle browser demo sets a manager and
never changes it, the rasterizer demo calls \texttt{enforceSecurity}
with a true argument the first time and a false argument the second
time, which enables then disables the sandbox. While this was an interesting
occurrence, there seems to be no valid reason to disable the sandbox
in this case other than to show off the capability to do so.

Ant, Freemind, and Netbeans explicitly set then change the manager
during runtime. Ant allows the users to create build scripts that
execute Java classes during a build under a user specified
permissions set. Figure \ref{fig:Ant Permissions Example}
shows an example permission set from the Ant Permissions website.%
\footnote{https://ant.apache.org/manual/Types/permissions.html%
} The contents of the \texttt{grant} element provide the application
all permissions, but the contents of the \texttt{revoke} element restrict
the application from using all property permissions. Due the use of a
defenseless security manager, malicious code can easily disable the sandbox and perform all actions
including those requiring \texttt{PropertyPermissions}.

\begin{figure}
\begin{lstlisting}[language=XML,basicstyle={\scriptsize}]
<permissions>   
  <grant class="java.security.AllPermission"/>   
  <revoke class="java.util.PropertyPermission"/> 
</permissions>
\end{lstlisting}

\caption{Example Ant build script element to grant all but one permission.
This specific permission set leads to a defenseless security manager.}
\label{fig:Ant Permissions Example}
\end{figure}

When Ant is about to execute an external, constrained class, it saves the current security manager and replaces it with a custom manager. The custom manager is not initially defenseless given a self-protecting permission set, but it contains a private switch to make the manager defenseless for the purposes of restoring the original manager. With this implementation, Ant catches applications that perform actions
restricted by the user while typically protecting sandbox settings. However, it is not clear this implementation
is free of vulnerabilities. Netbeans similarly sets a security manager around a separate application.

Both of these cases require a defenseless security manager, otherwise
the application would not be able to change the current security manager.
A better implementation would use a custom class
loader to load the untrusted classes into a constrained protection
domain. This approach would align with the intended usage of the sandbox.
Additionally, it would be more clearly correct and trustworthy while
allowing Ant and Netbeans to run inside of a self-protecting sandbox.

Freemind 0.9.0 tried to solve a similar problem but ended up illustrating
the dangers of a defenseless manager. Freemind is a mind mapping tool
that allows users to execute Groovy scripts on an opened map. The
scripts are written by the creator of the mind map. Groovy is a scripting
language that is built on top of the JRE: A Java application that
executes a script typically allows the script to execute in the same
JVM as the application itself. As a result, a mind map could potentially
be crafted to exploit a user that opens the map and runs its scripts.

\begin{figure}
\begin{lstlisting}[numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=30,xrightmargin={0.1cm},numbersep={-10pt}]
  /**  
   * By default, everything is allowed.  
   * But you can install a different security controller once,  
   * until you install it again. Thus, the code executed in   
   * between is securely controlled by that different security manager.  
   * Moreover, only by double registering the manager is removed. So, no   
   * malicious code can remove the active security manager.  
   *   
   * @author foltin  
   *  
   */
   public void setFinalSecurityManager(SecurityManager pFinalSecurityManager) {
	 if(pFinalSecurityManager == mFinalSecurityManager){
       mFinalSecurityManager = null;
	   return;
      } 		
      if(mFinalSecurityManager != null) {
      throw new SecurityException("There is a SecurityManager installed already."); 		
      } 		
      mFinalSecurityManager = pFinalSecurityManager;
    }	
\end{lstlisting}


\caption{Initialization of the field in Freemind's custom security manager
that stores the proxy security manager.}
\label{fig:Freemind-Security-Manager}
\end{figure}

Freemind attempted to implement an architecture that would allow the
sandbox to enforce a stricter policy on the Groovy scripts than on
the rest of Freemind. Their design centers around the use of a custom
security manager that is set as the system manager in the usual manner.
This custom manager contains a field that holds a proxy manager to be used during the execution of
scripts. In this design, all checks to the security manager are ultimately
deferred to the proxy manager set in this field. When
this field is set to \texttt{null}, the sandbox is effectively disabled
even though the system's manager is still set to the custom manager.

Figure \ref{fig:Freemind-Security-Manager} shows how Freemind sets
the proxy security manager field.
Once a manager is set, if \texttt{setFinalSecurityManager} is called
again with a different security manager, a \texttt{SecurityException}
is thrown, but calling the method with a reference to the set manager disables the sandbox. The comment implies this specific sequence
of operations was implemented to prevent malicious applications from
changing the settings of the sandbox.

The Freemind code responsible for initiating the execution of the
Groovy scripts sets a proxy security manager that does not allow unsigned
scripts to create network sockets, access the file-system, or execute
programs on the machine. The manager explicitly allows all other permissions by overriding permission check methods with implementations that do nothing. As a result, a malicious script can turn off the sandbox at any point.

We demonstrated that the custom security manager is easily removed
using reflection to show that the problem is more complex than simply
fixing permission checks related to setting the security manager. Figure \ref{fig:Example-Exploit-for-Freemind}
shows a Groovy exploit to turn off the manager. The script gets a reference to the system's manager
and its class. The class has the same type as the custom security
manager, thus the exploit gets a reference to the proxy manager field.
The field is made public to allow the exploit to reflectively \texttt{null}
it, disabling the sandbox to allow ``forbidden'' operations.

We sent a notice to the Freemind developers in August of 2014 to provide
them with our example exploit and to offer our advice in achieving
their desired outcome. 

\begin{figure}
\begin{lstlisting}[language=Java,basicstyle={\scriptsize},breaklines=true]
def sm = System.getSecurityManager() 
def sm_class = sm.getClass() 
def final_sm = sm_class.getDeclaredField("mFinalSecurityManager")
final_sm.setAccessible(true) 
final_sm.set(sm, null)
new File("hacked.txt").withWriter { out -> out.writeLine("HACKED!") }
\end{lstlisting}


\caption{Example exploit that breaks out of the scripting sandbox in Freemind
to execute arbitrary code.}
\label{fig:Example-Exploit-for-Freemind}
\end{figure}

\section{Rules for Fortifying the Sandbox}\label{sec:Rules-for-Fortifying}

Given the results of our investigation in Section \ref{sec:Security-Manager-Study}
and the discussion in Section \ref{sub:Java-Exploits}, we can fortify
the sandbox for applications that set a \emph{self-protecting} security
manager. In this section, we define two rules to stop Java exploits
from disabling the manager. These rules are backwards-compatible with
benign applications: the Privilege Escalation rule and the Security
Manager rule. 

\subsection{Privilege Escalation Rule}

The \textit{Privilege Escalation rule} ensures that, if a self-protecting
security manager is set for the application, a class may not directly
load a more privileged class. This rule is violated when the protection
domain of a loaded class implies a permission that is not implied
in the protection domain that loaded it. About half of recent exploits
break this rule to elevate the privileges of their payload class.

If all classes in the Java Virtual Machine (JVM) instance were loaded
at the start of an application, this rule would never be broken. However,
the JVM loads certain classes on demand, and some of the JVM classes
have the full privileges. Classes in
packages that are listed in the \texttt{package.access} property of
\texttt{java.security.Security} are not subject to this rule because they are intended to be
loaded when accessed by a trusted proxy class. 

\subsection{Security Manager Rule}

The \textit{Security Manager rule} states that the manager cannot
be changed if a \emph{self-protecting} security manager has been set
by the application. This rule is violated when code causes a change
in the sandbox's configuration, the goal of many exploits. This rule
is an implementation of the strong mitigation.

\section{Validating the Rules}\label{sec:Mitigations}

In Section \ref{sec:Security-Manager-Study}, we discussed four hypotheses about security manager usage in benign applications, each
of which, if validated, leads to a distinct mitigation. In Section
\ref{sec:Study-results}, we gave empirical evidence in support of
Hypothesis 3 and rejected all of the others. Along the way, we learned
practical lessons about how applications use the Java sandbox that
are useful to exploit mitigation implementers. 

In this section, we evaluate the protection merits and backwards-compatibility of the rules presented in Section \ref{sec:Rules-for-Fortifying} through an implementation of runtime monitors that enforce them. This evaluation was done in collaboration
with a large aerospace company.

Section \ref{sub:Implementation-Using-JVMTI} discusses how we implemented
our runtime monitors using JVMTI. Section \ref{sub:Effectiveness-at-Fortifying}
explains the methodology behind and results of an experiment we conducted
to determine how effective the rules are at stopping existing exploits without breaking benign applications. Finally, Section
\ref{sub:Related-Work-Mitigation} covers prior work related to Java exploit mitigations.

\subsection{Implementation Using JVMTI}\label{sub:Implementation-Using-JVMTI}

JVMTI is a native interface used to create
analysis tools such as profilers, debuggers, monitors, and thread
analyzers. Tools that use JVMTI are called agents, and are attached
to a running Java application at a configuration-specific point in
the application's lifecycle. The interface allows an agent to set
capabilities, enabling the tool to intercept events such as class
or thread creation, field access or modification, breakpoints, etc.

Our agent \footnote{Our agent is open source. An anonymized version
of the tool can be found at http://goo.gl/In6Di0} must intercept three events to enforce the Privilege Escalation
and Security Manager rules: \texttt{ClassPrepare}, \texttt{FieldAccess},
and \texttt{FieldModification}. Enforcement of these rules is discussed in subsections \ref{sub:Enforcing-the-Privilege} and \ref{sub:Enforcing-the-SecurityManager}.

The field events require JVMTI to turn off the JIT, which slows down program
execution enough that our monitors are not suitable for adoption on their
own. JVMTI implementations can avoid this limitation, but avoidance would likely
increase implementation complexity beyond what is reasonable for a diagnostic
interface. We are currently in communication with the OpenJDK developers on
their security-dev mailing list regarding enforcement of our rules in the JVM
itself to avoid overhead issues.
\todo{Note: I moved the next sentence from the intro, which was too long. It may
not belong here and definitely needs to be integrated into the surrounding text.}
 This implementation strategy is motivated by
two concerns: Existing mechanisms for monitoring the execution of Java
applications are either (1) insufficient to securely enforce the rules
(e.g. bytecode instrumentation) or, like JVMTI, (2) unacceptably degrade
performance by disabling the just-in-time compiler (JIT). 
\footnote{REVIEWERS: This discussion will be referenced in the final version of the paper. At this time, the OpenJDK developers are very receptive to the idea, were already considering implementing something similar to our SecurityManager rule, and have stated the lessons from the empirical study we shared with in an early manuscript of this paper are valuable to their efforts.}

\subsubsection{Enforcing the Privilege Escalation Rule}\label{sub:Enforcing-the-Privilege}

The Privilege Escalation rule is enforced by ensuring that classes
can only load or cause the loading of more privileged classes in restricted-access
packages after a self-protecting security manager has been set. \textit{Restricted-access
packages} are packages that are public but not intended to be directly
used by typical Java applications; they are meant for internal JRE
use only. These packages are listed in the \texttt{package.access}
property in the \texttt{java.security.Security} class. There are two
ways to unsafely and directly access packages listed in this property:
(1) exploit a vulnerability in a class that can access them or (2)
allow access via the \texttt{accessClassInPackage} permission.

Applications use JRE classes which call restricted access package
classes. Thus, we must allow JRE to load restricted-access packages
at runtime. For example, many of the classes in the \texttt{java.lang.reflect}
package are backed by classes in the \texttt{sun} package, which is
a restricted-access package containing the internal implementations
for many Java features. However, enforcing the Privilege Escalation
rule prevents exploits from elevating the privileges of their payloads
because the payloads can not be in restricted-access packages with
default JRE configurations. 

To enforce the Privilege Escalation rule, our agent registers for
the \texttt{ClassPrepare} event, which allows the agent to inspect
a class after it is fully loaded but just before any of its code is
executed. Assuming the loaded class is not in a restricted-access
package, the agent inspects the stack frame to determine which class
caused the new class to be loaded. The agent must then get the protection
domains for both classes to ensure the loaded class is not more privileged.

\subsubsection{Enforcing the SecurityManager Rule}\label{sub:Enforcing-the-SecurityManager}

The SecurityManager rule is enforced by monitoring every read from
and write to the \texttt{security} field of the \texttt{System} class:
This field stores the security manager that is used by protected code.
The agent implements the read and write monitors by respectively registering
\texttt{FieldAccess and FieldModification} events for the field. Typically
the field is accessed via \texttt{System.getSecurityManager()}
and modified using \texttt{System.setSecurityManager()}, but we must
monitor the field instead of instrumenting these methods to detect
type confusion attacks. 

The agent stores a shadow copy of the application's most recent security
manager to have a trusted copy of the manager that can be used to
check for rule violations. This copy is only
updated by the modification event, which receives the new manager
as a parameter from JVMTI whenever the event is triggered.

Modification events are used to detect any change to a self-protecting
security manager. When the field is written, the agent checks the
shadow copy of the manager. Assuming the shadow copy is \texttt{null},
the agent knows the manager is being set for the first time and checks
to see if the new manager is self-protecting. If the manager is self-protecting
the agent simply updates the shadow copy. Otherwise the agent stops monitoring the application because the rule does not apply in the presence of a defenseless manager. Any further changes to the self-protecting manager are logged.

Access events are used to detect type confusion attacks against the
manager. The modification event we register will not be triggered
when the manager is changed due to a type confusion attack. When a
type confusion attack is used to masquerade a malicious class as the
\texttt{System} class, the malicious copy will have different internal
JVM identifiers for the class itself and its methods. Even given these
differences, updating a field in one version of the class updates
the value the JVM stores for the field in both classes because \texttt{System} is static and both classes appear to have the same type. The
modification and access events are registered for specific field and
class identifiers, thus the events are not triggered for operations
on the malicious version. We leverage the mismatch this causes between
the set security manager and our shadow copy by checking to see if
the manager that is read in the access event has the same internal
JVM reference as our shadow copy. When the two references do not match,
the manager has been changed by a malicious class masquerading as
\texttt{System}. Type confusion attacks may also be used to masquerade
a class as a privileged class loader to elevate the privileges of
a payload class that disables the manager; this scenario is detected
by the modification event.


\subsection{Effectiveness at Fortifying the Sandbox}\label{sub:Effectiveness-at-Fortifying}

%%Need to integrate backwards-compatibility experiment here and mention proprietary applications tested through aerospace collaborator.

We performed an experiment to evaluate how effective our rules are
at blocking exploits that disable the sandbox. In our experiment,
we ran Java 7 exploits for the browser from Metasploit 4.10.0 on 64-bit
Windows 7 against the initial release of version 7 of the JRE. This
version of Metasploit contains twelve applets that are intended to
exploit JRE 7 or earlier, but two did not successfully run due to
Java exceptions we did not debug. Metasploit contains many Java exploits
outside of the subset we used, but the excluded exploits either only
work against long obsolete versions of the JRE or are not well positioned
to be used in drive-by downloads. 

We ran the ten exploits in our set under the following conditions:
(1) without the agent, (2) with the agent but only enforcing the Privilege
Escalation rule, and (3) while enforcing both rules. We tested the Privilege Escalation rule separately from the Security Manager rule because the latter stops all of the exploits on its own. All
ten of the exploits succeed against our JRE without the agent. Four
were stopped by the Privilege Escalation rule. All ten were stopped
when both rules were enforced. The exploits that were not stopped
by the Privilege Escalation rule were either type confusion exploits
or exploits that did not need to elevate the privileges of the payload
class. The payload class does not need elevated privileges when it
can directly access a privileged class to exploit. Table \ref{tab:Exploit-experiment-summary}
summarizes our results using the specific CVEs each exploit targeted.

\begin{table}
\protect\caption{Effectiveness test results.}\label{tab:Exploit-experiment-summary}


\centering{}%
\begin{tabular}{l>{\raggedright}p{3cm}l}
\toprule 
\textbf{CVE-ID} & \textbf{Privilege Escalation Monitor} & \textbf{Both Monitors}\tabularnewline
\midrule
2011-3544 & Attack Succeeded  & Attack Blocked\tabularnewline
2012-0507 & Attack Blocked & Attack Blocked\tabularnewline
2012-4681 & Attack Succeeded  & Attack Blocked\tabularnewline
2012-5076 & Attack Succeeded  & Attack Blocked\tabularnewline
2013-0422 & Attack Blocked & Attack Blocked\tabularnewline
2013-0431 & Attack Blocked & Attack Blocked\tabularnewline
2013-1488 & Attack Succeeded  & Attack Blocked\tabularnewline
2013-2423 & Attack Succeeded  & Attack Blocked\tabularnewline
2013-2460 & Attack Blocked & Attack Blocked\tabularnewline
2013-2465 & Attack Succeeded  & Attack Blocked\tabularnewline
\bottomrule
\end{tabular}
\end{table}

\subsection{Limitations}

Neither of these rules will stop all Java exploits. While the rules
catch all of the exploits in our set, some Java vulnerabilities can
be exploited to cause significant damage without disabling the security
manager. For example, our rules will not detect type confusion exploits
that mimic privileged classes to perform their operations directly.
However, our rules substantially improve Java sandbox security, and
future work will be able to build upon these results to create mitigation
techniques for additional types of exploits.


\section{Threats to Validity}

\subsection{Study limitations}\label{sub:Limitations-Study}
\subsubsection{Internal Validity}

Our results are dependent on accurately studying the source code of
applications and their comments. In most cases, security manager interactions
are easily understood, but there are a few particularly complex interactions
that may be misdiagnosed. Furthermore, we did not review all application
code, thus we may have taken a comment or some source code out of
context in larger applications. Finally, using two different reviewers
may lead to variations in the interpretations of some of the data. 

We mitigated these threats by using a checklist, FindBugs plugin, and JVMTI agent to
provide reviewers consistent processes for reviewing code
and validating their results. Furthermore,
we inspected entire source files that contained
security manager operations. We tested our tools and processes in a pilot study
to find and mitigate sources of inconsistencies.

\subsubsection{External Validity}

The study only includes open source applications. It is possible
that closed source applications interact with the security manager
in ways that we did not see in the open source community. However,
we inspected a few small applications with our aerospace collaborators.
We did not find any code that suggested this is the case. 

\subsubsection{Reliability}

While the majority of the study is easily replicable, GitHub search results are constantly
changing. Using GitHub to generate a new dataset using our method
would likely generate a different dataset. Furthermore, over the course of our security
manager study, two applications either became private repositories
or were removed from GitHub (FileManagerFtpHttpServer and Visor).

\section{Related work}
\label{sec:related}
% CLG: I know you guys like to put the related work inline, but it's just taking
% soooooo long to get to the actual meat of the paper.  Can we try it like this
% to see if it works?  I'll concede if you insist. 

\subsection{Study}

Several recent studies have examined the use of security libraries
and discovered rampant library misuse, which caused severe vulnerabilities.
Georgiev et al. uncovered vulnerabilities in dozens of security critical
applications caused by SSL library protocol violations \cite{georgiev12most-dangerous}.
These applications misconfigured high-level libraries such that the
high-level libraries misused low-level SSL libraries which in turn
failed silently. Somorovsky et al. demonstrate vulnerabilities in
11 security frameworks such that Security Assertion Markup Language
(SAML) assertions are not checked properly when certain API mis-orderings
are triggered \cite{somorovsky12breaking}. Li et al. examined browser-based
password managers and found that many of their features relied on
an incorrect version of the same-origin policy, which could allow
attackers to steal user credentials \cite{li2014emperor}. As far
as we are aware no study has examined Java applications' use of the
sandbox. Li Gong, the main designer of the Java security architecture,
admitted in a ten year retrospective on Java Security that he didn't
know how or how extensively the ``fine grained access control mechanism''
(i.e. the Java sandbox) is used \cite{gong2009java}. We fill in that
gap. 

\subsection{Mitigation}\label{sub:Related-Work-Mitigation}

Our rules increase the security of the sandbox
by effectively removing unnecessary features. Prior work has taken a different
approach, instead focusing on re-implementing the Java sandbox or
adding to the sandbox to increase security. Cappos et al. created
a new sandbox structure. They implemented a security isolated kernel
to separate sandboxed applications from the main system \cite{cappos_retaining_2010}.
They validated this structure by translating past Java CVEs into exploits
for the new kernel. Provos et al. describe a method of separating
privileges to reduce privilege escalation \cite{Provos-PrivilegeEscalation}.
Their approach is partially implemented in the Java security model.
Li and Srisa-an extended the Java sandbox by providing extra protection
for JNI calls \cite{li_quarantine:_2011}. Their implementation, Quarantine,
separates JNI accessible objects to a heap which contains extra protection
mechanisms. The performance of their mechanism is also measured using
DaCapo. Siefers et al. created a tool, Robusta, which separates JNI
code into another sandbox \cite{siefers_robusta:_2010}%
\begin{comment}
Cite TISSEC journal version of Robusta paper
\end{comment}
. Sun and Tan extend the Robusta technique to be JVM independent \cite{sun_jvm-portable_2012}. 

Java applets are the most common ways to transmit Java exploits. Detectors
have been created to identify drive-by downloads in JavaScript \cite{cova_detection_2010},
and in Adobe Flash \cite{ford_analyzing_2009}. Helmer et al. used
machine learning to identify malicious applets \cite{helmer_anomalous_2001}.
Their approach monitored system call traces to identify malicious
behavior after execution. However, this approach is entirely reactive.
Our approach terminates exploits when they attempt to break out of
the sandbox, before the exploit performs its payload. Schlumberger
et al. used machine learning and static analysis to identify common
exploit features in malicious applets \cite{schlumberger_jarhead_2012}.
Blasing et al. used static analysis and dynamic analysis of sandboxed
executions to detect malicious Android applications \cite{Blasing-AndriodSandbox}.
Unlike these automated approaches, our rules shows that unique
mitigation strategies can be created with a better understanding of
how applications interact with the sandbox. 


\section{Conclusion}

\todo{CLG moved the following two paragraphs from what used to be section 3; my
  thought is we could have a longer ``discussion'' of Java software development
  and its relationship to security, and I think these two paragraphs might fit
  in well there.}
Many of the recent type confusion and privilege escalation vulnerabilities
would not have been introduced if the JRE were developed strictly
following ``The CERT Oracle Secure Coding Standard for Java'' \cite{long_cert_2011}.
For example, Svoboda \cite{svoboda_anatomy_blog_2013,svoboda_anatomy_2014}
pointed out that CVE-2012-0507 and CVE-2012-4681 were caused by violating
a total of six different secure coding rules and four guidelines. 

In the typical case, following just one or two of the broken rules
and guidelines would have prevented a serious exploit. For example,
CVE-2012-4681 resulted from two rule violations in a privileged Abstract
Window Toolkit (AWT) class in the \texttt{sun} package and two rule
violations and an ignored guideline in a JavaBean class. The bean
class was exploited to access the AWT class. The AWT class contained
a method that reflectively fetched any field in any class, made the
field public, and returned it. This is a violation of rule SEC05-J
because reflection is being used to increase the accessibility of
fields. It is also a violation of SEC00-J because the AWT class is
privileged and leaks sensitive information (the fields) across trust
boundaries. The AWT class should have followed all of the secure coding
guidelines, but its violation of SEC00-J is especially problematic---the
exploits use the leaked fields to disable the security manager. 


Our study of Java sandbox usage in open-source applications found
that the majority of studied applications do not change the security
manager. Some of the remaining applications use the security manager
only for non-security purposes. The final set of applications use
the sandbox for security and either initialize a self-protecting security
manager and never modify it or set a defenseless manager and modify
it at run time. 

These findings, in combination with our analysis of recent Java exploits,
enabled us to define two rules which together successfully
defeated Metasploit's applet exploits without breaking backward compatibility with benign applications when enforced by an experimental JVMTI agent. Some of the studied applications
used the security manager to prevent third party components from calling
\texttt{System.exit()}. More generally, frameworks often need to enforce
constraints on plugins (e.g. to ensure non-interference). This suggests
that Java should provide a simpler, alternative mechanism for constraining
access to global resources. This is supported by our findings that
show developers attempting to make non-trivial use of the sandbox
often do so incorrectly. One intriguing possibility is to allow programmers
to strengthen the policy temporarily (e.g. by adding a permission). 

We indirectly observed many developers struggling to understand and
use the security manager for any purpose. This is perhaps why there
were only 46 applications in our sample. Some developers seemed to
misunderstand the interaction between policy files and the security
manager that enforces the policy. Other developers appear confused
about how permissions work. In particular, they do not realize that
restricting just one permission but allowing all others enables a
\emph{defenseless} sandbox. Our concerns are shared by the IntelliJ developers, who included static analysis checks to warn developers that a security expert should check their interactions with the security manager.\footnote{http://www.jetbrains.com/idea/documentation/inspections.jsp%
} In general, sandbox-defeating permissions
should be packaged and segregated to prevent accidental creation of
defenseless sandboxes. More generally, some developers appear to believe
the sandbox functions as a blacklist when, in reality, it is a whitelist.
These observations suggest that more resources---tool support, improved
documentation, or better error messages---should be dedicated to helping
developers correctly use the sandbox. 

\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}
