\documentclass{sig-alternate}
\usepackage[T1]{fontenc}
\usepackage{array}
\usepackage{verbatim}
\usepackage{booktabs}
\usepackage{fancyvrb}
\usepackage{url}
\usepackage[english]{babel}
\usepackage{listings}
\usepackage{myref}
\usepackage{todos}

\makeatletter
\makeatother

\begin{document}

%\author{BLINDED FOR SUBMISSION}

\title{Give 'em less rope: Open Source Evidence of Java Sandbox Perversions}

\numberofauthors{1} 
\author{\alignauthor Zack Coker, Michael Maass, Tianyuan Ding, Claire Le Goues, and Joshua Sunshine \\
\affaddr{Carnegie Mellon University} \\
\email{\{zfc,mmass\}@cs.cmu.edu, tding@cmu.edu, \{clegoues,sunshine\}@cs.cmu.edu}
} 

\maketitle
%JSS: This is to force page numbers.
\thispagestyle{plain} 
\pagestyle{plain}
\begin{abstract}
The ubiquitously-installed Java Runtime Environment (JRE) executes
untrusted code inside a sandbox to protect the host machine from potential
malicious behavior. However, dozens of recent exploits have successfully
escaped the sandbox, thereby enabling attackers to infect countless
Java hosts. It is essential to distinguish patterns of malicious use
from patterns of benign use to proactively prevent future exploits.
We therefore performed an empirical study of benign open-source Java
applications and compared their use of the sandbox to the usage present
in recent exploits. We found that benign applications with secured
sandboxes do not modify the security manager, the security policy
enforcement mechanism, after it is first set and do not attempt to
directly use privileged classes. Exploits routinely do both. We derive two rules from these results to prevent (1) security manager modifications and (2) privilege escalation. We evaluated their protection merits in a case study using runtime monitors to enforce the rules during the execution of exploits and benign applications. The rules stop all ten Metasploit Java 7 exploits without breaking backwards-compatibility with benign applications. These practical rules should be enforced in the JRE to fortify the Java sandbox.
\end{abstract}

\section{Introduction}


\begin{figure}
\begin{centering}
\includegraphics[width=2in]{most_targeted_apps_ibm_xforce}
\par\end{centering}
\caption{Pie chart showing the most
targeted applications on enterprise workstations, according to to
a Dec. 2013 survey of Trusteer customers \cite{xforceQ12013}. Java
\label{fig:most-targeted-applications}represented half of all attack-attempts in their sample.}
\end{figure}

Java applications are very popular targets for malicious attackers (see
Figure~\ref{fig:most-targeted-applications}), for three broad reasons.  First,
it is the Java Runtime Environment (JRE) is widely installed on user endpoints.
Second, the JRE can (and often does) execute external code, in the form of
applets and Java Web Start (JWS)~\cite{_java_web_start}
applications~\cite{gong1997going,gong2003inside}.  Finally, Java contains
hundreds of vulnerabilities \todo{Can we add raw numbers here, say over
  2011-2013?\\MM: I tried searching NVD (https://web.nvd.nist.gov/view/vuln/search-advanced), but this would only get us the number of CVE's. Unfortunately, NVD is erroring out instead of returning useful data. This would not tell us the actual number of vulnerabilities because a CVE can refer to many vulnerabilities. How important is this?}, including zero-day vulnerabilities (e.g. CVE-2013-0422).  In the
common scenario, often referred to as a ``drive-by download'', attackers lure
users to a website that contains a hidden malicious applet. Such malicious
applets exploit security vulnerabilities in the JRE to deliver malware,
typically leaving the user unaware.

In theory, such attacks should not be so common: 
Java provides a sandboxing mechanism that enables the safe execution of untrusted code and isolates
components another. Both the host application and host machine should
therefore be protected from malicious behavior on the part of
external code.  In practice, these security mechanisms are problematically
buggy, such that the sandbox often fails to properly contain external code. 
Java malware typically alters the sandbox's
settings~\cite{garber_2012}.  Such exploits take advantage of defects in either
the JRE's implementation the application's configuration of the sandbox to 
disable the security manager, the component of the sandbox responsible for enforcing the
security policy~\cite{fireeye_2013,svoboda_anatomy_blog_2013,security_explorations_2012,blackhat_2012}.

In this paper, we investigate this disconnect between theory and practice.  We
hypothesize that it results primarily from unnecessary complexity and flexibility
in the design and engineering of Java's security mechanisms.  \todo{Can someone
  flesh this out?  What types of complexity/flexibility does the sandbox allow
  that we don't need?  Likely relevant example: the ability to change the
  security manager at runtime. \\ MM: Added words.} For example, applications are allowed to change the security manager at runtime but static-only configuration of the manager would be more secure. The JRE also provides a number of permissions that are powerful enough that an application that uses one is essentially running without the sandbox. In particular, we
hypothesize that benign applications interact with the security manager in ways
that are measurably different from the ways that exploitative applications do.  
If true, this difference can be leveraged to prevent future attacks.

To validate these insights, we conducted an empirical study of benign open
source Java applications.  We sought to answer the research question: How do benign
applications interact with the Java security manager?  We identified 46
open-source Java projects that use the security manager, taken from the Qualitas
Corpus \cite{QualitasCorpus:APSEC:2010} and GitHub. For each project, we
isolated code that interacts with the security manager, manually characterized
those interactions, and constructed and used a Java Virtual Machine Tool Interface (JVMTI) agent
to confirm that our characterizations were accurate at runtime.

We discovered that there are two types of security managers used in
practice. \emph{Defenseless} security managers enforce a policy that allows code
inside the sandbox to modify sandbox settings.  Applications with defenseless
managers are inherently insecure, because externally-loaded malicious code can
modify or disable the security manager.  In our study, this situation typically
arose in applications that modified sandbox settings at runtime, often because
they use the security manager to enforce policies unrelated to security.
\todo{I think this train of thought needs one more observation, starting with
  something like ``this is interesting because''.  I'm drawing a blank on what
  should come after the ``because'', however, hence this todo.// MM: Added words.} It was not intended that the sandbox would be used to achieve these use cases, which effectively limit the set of potential exploit mitigations that are backwards-compatible with benign applications. Still, applications use the sandbox to fulfill requirements that do not improve the security of the application because Java does not provide better mechanisms for doing so. 
\emph{Self-protecting} security managers do not allow sandboxed code to modify
security settings.  The applications in our dataset with self-protecting
managers, including all applets and JWS applications, did not change those
settings over the course of execution.  It might still be possible to exploit
such applications due to defects in the JRE code that enforces security
policies, but not due to poorly-deployed local security settings.

In practice, applications that attempt to use the sandbox for its intended
purpose---protection from exploitative external code---do not make use of its
vast flexibility.  We therefore propose two runtime rules to fortify the Java
sandbox against the two most common modern attack types. We evaluate our rules
with respect to their ability to guard against the ten applets in Metasploit
4.10.0%
\footnote{http://www.metasploit.com/%
} that successfully exploit unpatched versions of Java 7. Taken together, the
monitors detected and stopped all ten exploits, and neither monitor produces
false-positives for a corpus of benign JWS applications.
We are engaged in an
on-going discussion on the security-dev mailing list for OpenJDK about
implementing runtime enforcement of these rules in the JVM itself.

The contributions of this papers are as follows:
\todo{CLG would like us to rethink these contributions once the rest of the paper
  has been modified.}
\begin{itemize}
\item An analysis of privilege escalation in the Java security model and
recent Java exploits (Section \ref{sub:Java-Exploits}).
\item An empirical study of Java sandbox usage in benign, open-source applications
(Sections \ref{sec:Security-Manager-Study} and \ref{sec:Study-results}).
\item Two novel rules for distinguishing between benign and malicious Java
programs (Section \ref{sec:Rules-for-Fortifying}).
\item A case study evaluation of the protection merits of our rules with a discussion of practical implementation considerations (Section \ref{sec:Mitigations}).
\end{itemize}

\section{Background}\label{sec:Background}

In this section, we describe the Java sandbox
(Section~\ref{sec:sandbox}), distinguish between defenseless and self-protecting
Security Managers (Section~\ref{sec:secmanagers}) and provide a high-level
description on how exploits commonly bypass these security mechanisms
(Section~\ref{sec:Java-Exploits}). 

\subsection{The Java sandbox}
\label{sec:sandbox}

\begin{figure}
\includegraphics[width=\columnwidth]{sandbox_overview}
\caption{High-level summary of the components of the Java 
\label{fig:Sandbox-high-level-summary}
sandbox.}
\end{figure}

The Java sandbox is designed to safely execute code from untrusted
sources. 
The relevant components are summarized in Figure
\ref{fig:Sandbox-high-level-summary}. 
When a \textit{class loader} loads a class (e.g., from
the network, filesystem, etc.), it assigns the class a \textit{code source} that
indicates the code origin, and associates it with a \textit{protection
  domain}. Protection domains segment the classes into groups by
\textit{permission set}. These sets
contain permissions that explicitly allow actions with security
implications, such as writing to the filesystem, accessing the network, using
certain reflection features, etc (see a more complete list
at~\cite{_permissions_2014}).  Unlisted actions are disallowed for classes in
that protection domain.  \emph{Policies}, written in the Java policy
language~\cite{_java_policy_language}, define the permission sets and the code
sources associated with them. 
By default, classes loaded from the local file system are run
without a sandbox; all other applications are run inside a restrictive
sandbox.  This prevents applications from the network or other untrusted sources
from executing malicious operations on the host system.

The sandbox is activated by setting a \emph{security manager}, which acts as the
gateway between the sandbox and the rest of the application. Whenever a
sandboxed class attempts to execute a method with security implications, that
method queries the security manager to determine if the operation should be
permitted.  We refer to such methods as \emph{privileged code}.  For example, if
a sandboxed application attempts to write to a file by using
\texttt{java.io.FileOutputStream}, the latter will first
check with the security manager to ensure that a write to that file is
permitted.  Missing checks in code that \emph{should} be protected are a common
source of Java vulnerabilities, because the security-critical code must initiate
the check.  Note that such vulnerabilities lie in the JVM itself (i.e., the code
written by the Java developers), not in the code that uses the sandbox to
execute untrusted external applications.

To perform a permission check, the security manager walks the call stack to
ensure each class in the current stack frame has the permissions necessary to
perform the action.  Consider a sandboxed class \texttt{Sandboxed} that attempts
to create a \texttt{java.io.FileOutputStream}. The \texttt{FileOutputStream}
constructor checks with the security manager to determine whether
\texttt{Sandboxed} has permission to open the file in question.  The manager
then checks the permission sets of each class in the call stack:
\texttt{FileOutputStream}, and then \texttt{Sandboxed}.  If the permission check
reaches a class in the stack frame that does not have the correct permissions,
the security manager will throw a \texttt{SecurityException}.  Privileged code,
such as \texttt{FileOutputStream} in our example, can wrap sensitive actions in
a \texttt{doPrivileged} call to preempt the stack check.  This allows privileged
code sections to perform actions with security implications at the request of
non-privileged code.\footnote{Stack-based access control is discussed in more
  detail
  in~\cite{banerjee_stack-based_2005,besson_stack_2004,d._s._wallach_understanding_1998,erlingsson_irm_2000,fournet_stack_2002,pistoia_beyond_2007,zhao_type_2005}.}

\subsection{Defenseless vs. self-protecting managers}
\label{sec:secmanagers}

\begin{table*}
\caption{List of sandbox-defeating permissions. A security manager that enforces
a policy containing any of these permission is sufficient to result
\label{tab:defenseless-permissions}
in a defenseless sandbox.}


\centering{}%
\begin{tabular}{ll}
\toprule 
\textbf{Permission} & \textbf{Risk}\tabularnewline
\midrule
RuntimePermission(``createClassLoader'') & Load classes into any protection domain\tabularnewline
RuntimePermission(``accessClassInPackage.sun'') & Access powerful restricted-access internal classes\tabularnewline
RuntimePermission(``setSecurityManager'') & Change the application's current security manager\tabularnewline
ReflectPermission(``suppressAccessChecks'') & Allow access to all class fields and methods as if they are public\tabularnewline
FilePermission(``<\textcompwordmark{}<ALL FILES>\textcompwordmark{}>'',
``write, execute'') & Write to or execute any file\tabularnewline
SecurityPermission(``setPolicy'') & Modify the application's permissions at will\tabularnewline
SecurityPermission(``setProperty.package.access'') & Make privileged internal classes accessible\tabularnewline
\bottomrule
\end{tabular}
\end{table*}

\todo{I think we need to hammer this point a bit more: Java's security model is
  too complicated---meaning it's implemented badly/in a way that's full of
  bugs---and also unecessarily so---because people don't need all that
  flexibility.  I'm not sure how to expand this text to help with that
  point-hammering, but I think it would be useful to the development of the
  argument.  Anyone see what I'm getting at and want to try to expand accordingly?}
 Java is flexible about when in an application's execution the sandbox
is configured and enabled. The default case for web applets and applications
that use Java Web Start is to set what we call a \textit{self-protecting} security
manager before loading the application from the network. The security
manager, and thus the sandbox, is self-protecting in the sense that
it does not allow the application to change sandbox settings. We contrast
self-protecting managers with those we call 
\textit{defenseless}, meaning that sandboxed applications have privileges that
permit them to modify or disable the security manager at runtime.  Such a
security manager is the exact opposite
of self-protecting. A defenseless manager is virtually useless in terms of improve the
security of either a constrained application or its host. However, we find
in Section~\ref{sec:Study-results} that the developers of some benign applications
have found interesting non-security uses for defenseless managers. 

Table~\ref{tab:defenseless-permissions} summarizes the set of permissions
used to distinguish between self-protecting and defenseless security
managers. We consider any security manager that enforces a policy
that contains any one of the listed permissions to be defenseless.
A subset of the permissions in this list were identified in \cite{security_explorations_2012}. 


\subsection{Exploiting Java Code}
 \label{sec:Java-Exploits}

\iffalse
\begin{figure}
\begin{centering}
\begin{lstlisting}[language=Java,basicstyle={\scriptsize}]
import java.lang.reflect.Method; 
import java.security.AccessController; 
import java.security.PrivilegedExceptionAction;   

public class Payload 
        implements PrivilegedExceptionAction {         
    public Payload() {
        try {
            AccessController.doPrivileged(this);
        } catch(Exception exception) { }     
    }

    public void run() {
        // Disable sandbox
        System.setSecurityManager(null);
    }

    public static void outSandbox() {
        // Do malicious operations
    }
}
\end{lstlisting}

\par\end{centering}

\caption{A typical sandbox-disabling  \label{fig:A-typical-exploit-payload}
Java exploit payload from http://pastebin.com/QWU1rqjf.}
% CLG isn't convinced that this figure is adding enough to justify the amount of
% space it's taking up.
\end{figure}
\fi

% Between 2011 and 2013, drive-by 
% downloads that used Java applets as the vector were widely reported.\todo{needs
%   a reference.  Also, I'm considering killing this sentence, but haven't decided
% yet.}
%
% This section provides an analysis of privilege escalation in the Java
% security model and recent Java exploits. 
While the Java sandbox \textit{should} prevent malicious applets from
executing their payloads, defects in the
Java Runtime Environment (JRE) enforcement of these security mechanisms permit
malicious code to set a security manager to \texttt{null}.  
Setting the security manager to \texttt{null} disables the sandbox, allowing
previously constrained classes to perform operations with the privileges of 
the JRE itself. 
This approach was taken in a large proportion of drive-by downloads exploiting
Java applets between 2011 and 2013~\cite{fixme-metasploit}. 
%Figure \ref{fig:A-typical-exploit-payload}
%shows a typical payload class whose privileges have been elevated
%by an exploit to allow it to disable the sandbox. This example payload
%uses \texttt{doPrivileged} to allow the unprivileged exploit class
%to execute the operations in the payload without causing a \texttt{SecurityException}.
%
There are a couple of methods by which an exploit may nullify a security manager:

\noindent\textbf{Type confusion.} An attacker breaks type
safety to craft an object that can perform operations as if it had
a different type. Commonly, attackers craft objects that either
(1) point to the \texttt{System} class or (2) act as if they had
the same type as a privileged class loader (see CVE-2012-0507 \cite{_vulnerability_2012_0507}).
In the first case, any operation performed on the
masqueraded class is applied to the real \texttt{System} class, allowing
the attacker to directly alter the field storing the security manager. 
In the second case, the malicious class can load an exploitative
payload with elevated privileges.

\noindent\textbf{Confused deputy.} Exploitative code ``convinces'' another
class to return a reference to a privileged class~\cite{hardy_confused_1988}
known to contain a vulnerability (such as a missing security check).  The
attacker then takes advantage of that vulnerability to disable the sandbox 
(see CVE-2012-4681 \cite{_vulnerability_2012_4681}).
The ``convincing'' is necessary
because it is rare that a vulnerable privilege class is directly accessible
to all Java applications; doing so violates the \textit{access
control} principle that is part of the Java development culture.%
\footnote{\url{https://blogs.oracle.com/jrose/entry/the_isthmus_in_the_vm}%
} Once an exploit gains access to a vulnerable privileged class, that
class can be ``tricked'' into executing code that disables the sandbox

The confused deputy attack is an example of privilege escalation.  Most
privileged classes in the JRE implement features that can be accessed via
less-privileged code paths; benign applications therefore rarely need to
directly access them. 
%
%  For example, the \texttt{sun.reflect} package implements
% reflection operations; it also has all permissions. However, Java applications
% do not have direct access to the \texttt{sun} classes with default JRE
% configurations; instead, they are expected to use classes in the
% \texttt{java.lang.reflect} package to use reflection.  The \texttt{java} package
% classes do not perform privileged operations, but do have access to the
% privileged classes in the \texttt{sun} package.
Because a privileged class loader must be used to load a privileged class, 
a non-privileged class does not typically have access to vulnerable
privileged classes anyway. The danger of vulnerabilities in privileged
classes is therefore mitigated, because such vulnerabilites cannot be exploited
directly unless malicious code succeeds in modifying its privileges first. 
This redundancy is implicit in the Java security model: If any class
could load more privileged classes and directly cause the execution
of privileged operations, the sandbox in its current form would serve
little purpose. In sections \ref{sec:Rules-for-Fortifying} and \ref{sec:Mitigations}
we discuss how we can leverage these distinctions to further fortify
the sandbox.

% In the rest of this paper, we do not concern ourselves with the specifics of
% particular exploits. We will now explore how benign applications interact with
% the sandbox to define ways of delineating them from exploits.


\section{Security Manager Study}\label{sec:Security-Manager-Study}

Modern exploits that manipulate on the Java security manager perform one
operation: They disable it.  This is possible because the Java security model is extremely
complex and grants enormous flexibility to application developers to
set, reconfigure, manipulate, weaken, strengthen, or otherwise change a security
manager after it has been created.
Do applications need this power?  Do they regularly take advantage of the
ability to disable or weaken the sandbox?  If not, we can design
backwards-compatible JVM enhancements that can stop even zero-day exploits by
eliminating the operations on which exploits depend.  \todo{CLG says: I'm not
  sure I understand this sentence, but I think it's important.  Can we simplify
  it? This strategy would allow the sandbox to enforce policies on a given
  execution without having to deal with the wide diversity in the manifestations
  of vulnerabilities within the JRE or the subtleties of their exploits. } 

In this section, we describe an empirical analysis consisting of static,
dynamic, and manual inspections of the open source Java application landscape
that aims to understand the operations benign applications perform on the
manager. We focus our efforts on the security manager, as it is the
means by which applications interact with the sandbox.
%
Our basic research question is: How do benign open source Java applications interact
with the security manager? The answer to this question informs which JVM-level
modifications can be deployed to mitigate the ability of exploitative code to
nullify the security manager while maintaining backwards compatibility.  The
possible mitigations vary in the strength with which they will be able to stop
exploits. 
% For example, a ``weak'' mitigation stops a small number of in-scope
% exploits and is easily bypassed.  An ``ideal'' mitigation stops all in-scope
% exploits and can never be bypassed.  
There are four possibilities:
\begin{flushenum}	\setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
  \setlength{\itemsep}{0pt}
\item \textit{Benign applications never disable the security manager.}  If true,
  only exploitative code attempts to disable the security manager once it is set.
  The JVM could mitigate this risk by eliminating an application's ability to
  do so.  This would be easy to implement, but would not guard against exploits
  that weaken the sandbox without disabling it.
% For example, attackers could potentially bypass the mitigation
% by modifying the enforced policy to allow the permissions they need
% or they could replace the current manager with one that never throws
% a \texttt{SecurityException}.
\item \textit{Benign applications do not weaken a set security manager}.  If
  true, the JVM could be modified to prevent any weakening or disabling of the 
  sandbox once it's set.  This is more powerful than simply removing the
  ability to disable the security manager, but is significantly more difficult to
  implement.
  % However, this would require the ability to
  % differentiate between changes that weaken the sandbox and those that do not,
  % a difficult problem.
  % Classifying changes in this manner autonomously is difficult
  % because it requires context specific information that a general mitigation
  % strategy may not have. 
  For example, if a permission to write to a file is
  replaced by a permission to write to a different file, is the sandbox
  weakened, strengthened, or exactly as secure as it was before?
\item \textit{Benign applications never modify the sandbox if a self-protecting
    security manager has been set}. If true, the JVM could be modified to
  disallow any change to a self-protecting security manager, defined by the
  policy it enforces.  This could be implemented with a runtime monitor that
  determines if a security manager is self-protecting when an application
  attempts to change the sandbox. This is much easier to implement soundly than
  the previous possible mitigation and guards against the same number and types of
  exploits.
  % This can
  % be easily achieved. While this mitigation has the same outcome as the moderate
  % mitigation, it is significantly easier to implement soundly and it is
  % therefore more likely to be effective in practice.
\item \textit{Benign applications do not change a set security manager.} If
  true, any attempted change to an already established security manager can be
  considered malicious. This would be the ideal result: restricting this
  operation is easy to implement in the JVM.
\end{flushenum}

In this section, we describe the
methodology for and limitations of our empirical study
study on open-source Java projects to validate this strategy, answer our
motivating question, and provide data in support of JVM enhancements to fortify
the Java sandbox.  

\subsection{Dataset}\label{sec:Applications-Studied}

\begin{table}
\caption{Security manager dataset.\label{Table:applications-studied}}
\begin{tabular}{lll}
\toprule 
Application Name & Description & Repo\tabularnewline
\midrule
(Apache) Ant & Java Project Builder & QC\tabularnewline
(Apache) Batik & SVG Image Toolkit & QC\tabularnewline
%C-JDBC & DB Cluster Middleware & QC\tabularnewline
%Compiere & Business Tools & QC\tabularnewline
(Apache) Derby & Relational Database & QC\tabularnewline
%DrJava & IDE & QC\tabularnewline
Eclipse  & IDE & QC\tabularnewline
FreeMind & Mind-Mapping Tool & QC\tabularnewline
Galleon & Media Server & QC\tabularnewline
(Apache) Hadoop & Distrib. Comp. Frwk. & QC\tabularnewline
Hibernate & Obj.-Rel. Mapper & QC\tabularnewline
%HyperSQL & SQL DB & QC\tabularnewline
JBoss & Application Middleware & QC\tabularnewline
JRuby & Ruby Interpreter & QC\tabularnewline
(Apache) Lucene & Search Software & QC\tabularnewline
(Apache) MyFaces & Server Software & QC\tabularnewline
NekoHTML & HTML Parser & QC\tabularnewline
Netbeans & IDE & QC\tabularnewline
OpenJMS & Messaging Service & QC\tabularnewline
Quartz  & Job Scheduler & QC\tabularnewline
QuickServer & TCP Server Frwk. & QC\tabularnewline
Spring Framework & Web Dev. Library & QC\tabularnewline
(Apache) Struts & Web Dev. Library & QC\tabularnewline
%(Apache) Tapestry & Web Dev. Library & QC\tabularnewline
(Apache) Tomcat & Web Server & QC\tabularnewline
Vuze & File Sharing App. & QC\tabularnewline
Weka & Machine Learning Algs. & QC\tabularnewline
(Apache) Xalan & XML Trans. Library & QC\tabularnewline
(Apache) Xerces & XML Parsing Library & QC\tabularnewline
AspectJ & Java Extension & Github\tabularnewline
%DemoPermissions & Spring Extension & Github\tabularnewline
driveddoc & Application Connector & Github\tabularnewline
%FileManager- & FTP Server & Github \\ FtpHttpServer\tabularnewline
Gjman & Development Toolkit & Github\tabularnewline
IntelliJ IDEA & IDE & Github\tabularnewline
%Jmin & Lightweight JDK & Github\tabularnewline
%MCVersion-Control & Minecraft Utility & Github\tabularnewline
%NGOMS & Business Tools & Github\tabularnewline
oxygen-libcore & Android Dev. Lib. & Github\tabularnewline
refact4j & Meta-model Prog. Frwk. & Github\tabularnewline
Security-Manager & Alt. Security Manager & Github\tabularnewline
Spring-Modules & Spring Extension & Github\tabularnewline
System Rules & JUnit Extension & Github\tabularnewline
TimeLag & Sound Application & Github\tabularnewline
TracEE & JavaEE Support Tool & Github\tabularnewline
Visor & Closure Library & Github\tabularnewline
\bottomrule
\end{tabular}
\end{table}

We used applications from the Qualitas Corpus (QC)
\cite{QualitasCorpus:APSEC:2010} and GitHub to form a dataset of applications
that use the security manager.  The Qualitas Corpus is a curated collection of
open source Java applications for use in reproducible software studies.  While
QC provides a strong starting point for the construction of a dataset for this
study, their inclusion criteria%
\footnote{http://qualitascorpus.com/docs/criteria.html%
} means it is comprised largely of large, popular applications and frameworks.
We diversified our dataset by including applications from GitHub. Table
\ref{Table:applications-studied} lists all studied applications. Version numbers
and Git commit hashes are available in an online supplement.%
\footnote{http://goo.gl/dtcqTM%
} 

We investigated sandbox interactions in 29 of the 112 applications from QC
version 20130901.  We used \texttt{grep} on the source code of the full set
to find instances of the keyword \texttt{SecurityManager}, which
identified 29 applications of interest.  We performed a similar process on
GitHub, searching only Java files. We added the keyword
\texttt{System.setSecurityManager(} to remove false positives, and
\texttt{System.setSecurityManager(null)} to find applications that disable the
manager. We picked the top seven applications from the results for each keyword,
removed false positives, resulting in an additional 17 applications that
were not already in QC. We only looked at the latest commit \todo{as of when?}.

\subsection{Methodology}

We created static and dynamic analysis tools
to assist in the manual inspection of each application's security manager
interactions. We created a 
FindBugs \cite{hovemeyer_finding_2004} plugin
that uses dataflow analysis to identify the initialization of and calls to \texttt{System.setSecurityManager}().
We created a dynamic analysis tool using the Java Virtual Machine
Tool Interface (JVMTI) \cite{_jvmti}, which allows
tools to inspect the current state of Java applications and control
their execution. Our dynamic analysis tool set a modification watch
on the \texttt{security} field of Java's \texttt{System} class. This
field holds the current security manager object for the application.
% The watch prints out the class name, source file name, and line of
% code where any change to the field took place. A special notice is
% printed when the field is set to \texttt{null}. 

We split the dataset between two reviewers, who each analyzed
applications using the following steps:

\begin{flushenum}\setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
  \setlength{\itemsep}{0pt}
\item Run \texttt{grep} on all Java source files in the application.
Output every line containing the keyword \texttt{SecurityManager} and the 5
lines before and after it.  Manually inspect the returned code with respect to
how the application interacts with the sandbox.
\item Run the static analysis on retained applications. Manually inspect the
  returned code, focusing on initialization. 
\item Execute the application with the dynamic analysis using parameters
  informed by the previous steps, 
to verify conclusions.
\item Summarize operations performed
on the security manager.
\end{flushenum}

We undertook a pilot study where each reviewer
independently inspected the same six applications and compared their
results. This ensured reviewers understood the analysis steps and produced
consistent results.


\section{Study Results}\label{sec:Study-results}

In this section, we describe the results of our empirical study of open-source
Java programs and how they interact with the security manager. \todo{actual road map}

\subsection{Summary of benign behaviors}\label{sub:Evaluation-of-the-hypotheses}


\begin{table}
\caption{Classification of application
  interactions \label{tab:Classification-of-Application}
with the security manager.}
\begin{tabular}{lrrr}
\toprule 
Type of Interaction & QC & GitHub & Total\tabularnewline
\midrule
1. Sets manager, nothing else & 6 & 1 & 7\tabularnewline
2. Changes set security manager & 5 & 3 & 8\tabularnewline
3. Support being sandboxed & 10 & 3 & 13\tabularnewline
4. Interactions only in unit tests & 3 & 5 & 8\tabularnewline
%5. No interactions (false positive) & 5 & 5 & 10\tabularnewline
\bottomrule
\end{tabular}
\end{table}

\todo{How many applications set or require a defenseless manager?  Is that interesting?}

Recall that in Section~\ref{sec:Security-Manager-Study}, we refined the
high-level research question---how do benign applications interact with the
security manager?---into four possibilities, and that the possible mitigations
required in each case varied by strength and complexity.  Revisiting those
possibilities with respect to our dataset, we found that:
\begin{flushenum}\setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
  \setlength{\itemsep}{0pt}
\item Benign applications \emph{do} sometimes disable the security manager.
  However, we found that such applications typically use the sandbox for
  non-security purposes; we discuss further below.

\item Several benign applications \emph{do} provide methods for the user to
  dynamically change the security policy or the manager in ways that can reduce
  the security of the sandbox.

\item Benign applications do \emph{not} change the
security manager if a self-protecting security manager has been set.  

\item Benign applications do sometimes change a set security manager.  We
  observed multiple applications that changed a set security manager.
\end{flushenum}

The strong mitigation is thus the only proposed mitigation that can be
implemented without breaking the benign applications in our dataset;
fortunately, the implementation does not require complex, context-sensitive
information about whether a change to a policy weakens the sandbox or not. 

We characterize each application in our dataset along one of four types, depending on how they
interact with the security manager:
(1) applications that set a
security manager that does not get changed later in the application's
execution, (2) applications that change a set manager at some point
in the program's execution, (3) applications that interact with a
security manager in production code if one is set but do not modify the manager
or its policy, and (4) applications
that only interact with the manager in unit tests. 

Table \ref{tab:Classification-of-Application}
summarizes our dataset using these types. \todo{one-sentence summary}  We will
not discuss types 3 or 4 applications further, because their interactions with
the sandbox are not interesting from the perspective of improving the JVM to
reduce security vulnerabilities: none of the considered mitigations could break
backwards-compatability.  

Of the four categories, Type 2 applications are the most interesting, because
they change pre-configured and running security managers.  We therefore focus
on these applications therefore in our discussion. A few Type 1
applications also provide interesting insights into
benign sandbox interactions. We discuss application that use the sandbox for
purposes that are not security related in Section \ref{sub:Non-security-uses-of}
and applications that use the sandbox for its intended security purposes in
Section \ref{sub:Using-the-Security}.

\subsection{Non-security uses of the Sandbox}\label{sub:Non-security-uses-of}

\begin{figure}
\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=691,xrightmargin={0.1cm},numbersep={-10pt}]
    System.setSecurityManager(new AntSecurityManager(originalSM, Thread.currentThread()));
    ...
\end{lstlisting}
\vspace{-0.3cm}
\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=703,xrightmargin={0.1cm},numbersep={-10pt}]
    getCurrentProject().executeTargets(targets); //Note: Ant is executed on this line
    ...
\end{lstlisting}
\vspace{-0.3cm}
\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=721,xrightmargin={0.1cm},numbersep={-10pt}]
    finally {
    ...
\end{lstlisting}
\vspace{-0.3cm}
\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=725,xrightmargin={0.1cm},numbersep={-10pt}]
      if (System.getSecurityManager() instanceof AntSecurityManager) { 
          System.setSecurityManager(originalSM); 
      }
\end{lstlisting}
\protect\caption{Snippet of Eclipse code that uses a security manager to prevent Ant\label{fig:Eclipse-snippet}
from terminating the JVM.}
\end{figure}

This section describes applications that interact with the sandbox in ways that
are not related to security. Most of these applications used the
sandbox to enforce architectural constraints when interacting with
other applications, or forcibly disabled the sandbox to reduce development
complexity.  \todo{These applications are interesting because --- CLG thinks it
  might be desireable to put such a discussion into an explicit ``discussion''
  or conclusions section, but put in this todo just to remember to think about it}.

\noindent\textbf{Enforcing Architectural Constraints}
%
Java applications often call \texttt{System.exit()} when a non-recoverable
error occurs. This is problematic when the application in question is 
used as a library: The \texttt{System.exit()} will close the calling
application as well, because both applications
are running in the same JVM. This is often not the desired
outcome.
%
To prevent this outcome without modifying the library application,
the calling application needs to enforce the architectural constraint
that libraries cannot terminate the JVM. 

Some applications
enforce this constraint by setting a security manager
that prevents \texttt{System.exit()} calls.
We found 3 applications that use a variation of this technique:
Eclipse, GJMan, and AspectJ.\footnote{%
GJMan contains a code comment referencing a
blog post that we believe is the origin of this solution. \url{http://www.jroller.com/ethdsy/entry/disabling\_system\_exit}}
For example, Eclipse uses Ant as a library.  Ant calls \texttt{System.exit()} to
terminate a currently-running build script in the event of an unrecoverable
error.  However, when Eclipse uses Ant as a library, it
should instead continue to execute, and report an error to the user.
Figure~\ref{fig:Eclipse-snippet} shows
how Eclipse sets a security manager to enforce this constraint
before executing Ant. After Ant closes and any error conditions
are handled, Eclipse restores the original manager.

While this technique does enforce the
desired constraint, and appears to be the best solution available
in Java at the moment, it is problematic for applications that also 
use the sandbox as intended, for security purposes. The technique requires
the application to dynamically change the security manager, which requires either a defenseless manager or for the application
to be carefully written to prevent malicious code from weakening the sandbox. Defenseless security managers
are not capable of reliably enforcing a serious security policy.

\noindent\textbf{Reducing Web Application Development Complexity}%\label{sub:Reducing-Web-Application-Complexity}
%
We also found applications that were complicated by the Java security policies
for web applications (applets and applications launched via JWS). By default,
Java executes such applications inside a restrictive 
sandbox, 
excluding operations such as accessing local files, retrieving resources
from any third party server, or changing the security manager. 

Applications in our set that cannot run in a restrictive sandbox universally
opted to run outside of the sandbox, because the alternative is to painstakingly
construct the application to run reasonably without required privileges (e.g. by
detecting the sandbox and disabling privileged operations). To avoid executing
the applet in a restrictive 
sandbox, a developer must get the application digitally signed
by a recognized certificate authority then specify that the application should
run outside of the sandbox. We found that applications using this method attempted
to set the security manager to \texttt{null} at the beginning of the
application, causing a restrictive sandbox to catch the security violation and
terminate the application.

We found two applications that do this: Eclipse and
Timelag. The rationale for disabling the manager in Eclipse is explained in a
code comment that reads, ``The launcher to start eclipse using webstart. To use
this launcher, the client must accept to give all security permissions.'' Timelag
performs the same operation but does not contain any comments, thus we can only
infer the developers' motivations. 

\subsection{Using the Security Manager for Security Purposes}
\label{sub:Using-the-Security}

This section describes applications that provide novel insights into benign sandbox interactions related to improving the security
posture of the application. Several of these applications clearly violate hypotheses 1, 2, and 4: Batik, Eclipse, and Spring-modules provide
methods that allow the user to set and change an existing manager,
and Ant, Freemind, and Netbeans explicitly set then change the manager.

\begin{figure}
\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=156,xrightmargin={0.1cm},numbersep={-10pt}]
    public void enforceSecurity(boolean enforce){ 
    SecurityManager sm = System.getSecurityManager();

    if (sm != null && sm != lastSecurityManagerInstalled){
        ...
\end{lstlisting}


\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=163,xrightmargin={0.1cm},numbersep={-10pt}]
        throw new SecurityException
            (Messages.getString(EXCEPTION_ALIEN_SECURITY_MANAGER));   
    }                  
    if (enforce) { 
        ...
\end{lstlisting}


\begin{lstlisting}[language=Java,numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=173,xrightmargin={0.1cm},numbersep={-10pt}]
        installSecurityManager();         
    } else {             
        if (sm != null) {                 
           System.setSecurityManager(null);
           lastSecurityManagerInstalled = null;             
           ...
\end{lstlisting}


\protect\caption{Security manager interactions in Batik.}\label{fig:Batik-snippet}
\end{figure}


Figure \ref{fig:Batik-snippet} shows an interesting case from Batik
copied from \texttt{ApplicationSecurityEnforcer.java}. This method
allows users to optionally constrain the execution of an an application
that uses the Batik SVG Toolkit. It takes a parameter that acts as
a switch to turn the sandbox on or off. The download page on the Batik
website shows several examples of how to use the library. Two set
a security manager at start up: the squiggle browser demo and the
rasterizer demo. While the squiggle browser demo sets a manager and
never changes it, the rasterizer demo calls \texttt{enforceSecurity}
with a true argument the first time and a false argument the second
time, which enables then disables the sandbox. While this was an interesting
occurrence, there seems to be no valid reason to disable the sandbox
in this case other than to show off the capability to do so.

Ant, Freemind, and Netbeans explicitly set then change the manager
during runtime. Ant allows the users to create build scripts that
execute Java classes during a build under a user specified
permissions set. Figure \ref{fig:Ant Permissions Example}
shows an example permission set from the Ant Permissions website.%
\footnote{https://ant.apache.org/manual/Types/permissions.html%
} The contents of the \texttt{grant} element provide the application
all permissions, but the contents of the \texttt{revoke} element restrict
the application from using all property permissions. Due the use of a
defenseless security manager, malicious code can easily disable the sandbox and perform all actions
including those requiring \texttt{PropertyPermissions}.

\begin{figure}
\begin{lstlisting}[language=XML,basicstyle={\scriptsize}]
<permissions>   
  <grant class="java.security.AllPermission"/>   
  <revoke class="java.util.PropertyPermission"/> 
</permissions>
\end{lstlisting}

\caption{Example Ant build script element to grant all but one permission.
This permission set results in a defenseless security manager.}
\label{fig:Ant Permissions Example}
\end{figure}

When Ant is about to execute an external, constrained class, it saves the current security manager and replaces it with a custom manager. The custom manager is not initially defenseless given a self-protecting permission set, but it contains a private switch to make the manager defenseless for the purposes of restoring the original manager. With this implementation, Ant catches applications that perform actions
restricted by the user while typically protecting sandbox settings. However, it is not clear this implementation
is free of vulnerabilities. Netbeans similarly sets a security manager around a separate application.

Both of these cases require a defenseless security manager, otherwise
the application would not be able to change the current security manager.
A better implementation would use a custom class
loader to load the untrusted classes into a constrained protection
domain. This approach would align with the intended usage of the sandbox.
Additionally, it would be more clearly correct and trustworthy while
allowing Ant and Netbeans to run inside of a self-protecting sandbox.

Freemind 0.9.0 tried to solve a similar problem but ended up illustrating
the dangers of a defenseless manager. Freemind is a mind mapping tool
that allows users to execute Groovy scripts on an opened map. The
scripts are written by the creator of the mind map. Groovy is a scripting
language that is built on top of the JRE: A Java application that
executes a script typically allows the script to execute in the same
JVM as the application itself. As a result, a mind map could potentially
be crafted to exploit a user that opens the map and runs its scripts.

\begin{figure}
\begin{lstlisting}[numbers=left,basicstyle={\scriptsize},breaklines=true,firstnumber=32,xrightmargin={0.1cm},numbersep={-10pt}]
  /** By default, everything is allowed.  
   * But you can install a different security controller once,  
   * until you install it again. Thus, the code executed in   
   * between is securely controlled by that different security manager.  
   * Moreover, only by double registering the manager is removed. So, no   
   * malicious code can remove the active security manager.  
   * @author foltin  
    */
  public void setFinalSecurityManager(SecurityManager pFinalSecurityManager) {
    if(pFinalSecurityManager == mFinalSecurityManager){
      mFinalSecurityManager = null;
      return;
     } 		
     if(mFinalSecurityManager != null) {
     throw new SecurityException("There is a SecurityManager installed already."); 		
     } 		
     mFinalSecurityManager = pFinalSecurityManager;
   }	
\end{lstlisting}


\caption{Initialization of the field in Freemind's custom security manager
that stores the proxy security manager.}
\label{fig:Freemind-Security-Manager}
\end{figure}

Freemind attempted to implement an architecture that would allow the
sandbox to enforce a stricter policy on the Groovy scripts than on
the rest of Freemind. Their design centers around the use of a custom
security manager that is set as the system manager in the usual manner.
This custom manager contains a field that holds a proxy manager to be used during the execution of
scripts. In this design, all checks to the security manager are ultimately
deferred to the proxy manager set in this field. When
this field is set to \texttt{null}, the sandbox is effectively disabled
even though the system's manager is still set to the custom manager.

Figure \ref{fig:Freemind-Security-Manager} shows how Freemind sets
the proxy security manager field.
Once a manager is set, if \texttt{setFinalSecurityManager} is called
again with a different security manager, a \texttt{SecurityException}
is thrown, but calling the method with a reference to the set manager disables the sandbox. The comment implies this specific sequence
of operations was implemented to prevent malicious applications from
changing the settings of the sandbox.

The Freemind code responsible for initiating the execution of the
Groovy scripts sets a proxy security manager that does not allow unsigned
scripts to create network sockets, access the file-system, or execute
programs on the machine. The manager explicitly allows all other permissions by overriding permission check methods with implementations that do nothing. As a result, a malicious script can turn off the sandbox at any point.

We demonstrated that the custom security manager is easily removed
using reflection to show that the problem is more complex than simply
fixing permission checks related to setting the security manager. Figure \ref{fig:Example-Exploit-for-Freemind}
shows a Groovy exploit to turn off the manager. The script gets a reference to the system's manager
and its class. The class has the same type as the custom security
manager, thus the exploit gets a reference to the proxy manager field.
The field is made public to allow the exploit to reflectively \texttt{null}
it, disabling the sandbox to allow ``forbidden'' operations.

We sent a notice to the Freemind developers in August of 2014 to provide
them with our example exploit and to offer our advice in achieving
their desired outcome. 

\begin{figure}
\begin{lstlisting}[language=Java,basicstyle={\scriptsize},breaklines=true]
def sm = System.getSecurityManager() 
def sm_class = sm.getClass() 
def final_sm = sm_class.getDeclaredField("mFinalSecurityManager")
final_sm.setAccessible(true) 
final_sm.set(sm, null)
new File("hacked.txt").withWriter { out -> out.writeLine("HACKED!") }
\end{lstlisting}


\caption{Example exploit that breaks out of the scripting sandbox in Freemind
to execute arbitrary code.}
\label{fig:Example-Exploit-for-Freemind}
\end{figure}

\section{Rules for Fortifying the Sandbox}\label{sec:Rules-for-Fortifying}

Given the results of our investigation in Section \ref{sec:Security-Manager-Study}
and the discussion in Section \ref{sub:Java-Exploits}, we can fortify
the sandbox for applications that set a \emph{self-protecting} security
manager. In this section, we define two rules to stop Java exploits
from disabling the manager. These rules are backwards-compatible with
benign applications: the Privilege Escalation rule and the Security
Manager rule. 

\subsection{Privilege Escalation Rule}

The \textit{Privilege Escalation rule} ensures that, if a self-protecting
security manager is set for the application, a class may not directly
load a more privileged class. This rule is violated when the protection
domain of a loaded class implies a permission that is not implied
in the protection domain that loaded it. About half of recent exploits
break this rule to elevate the privileges of their payload class.

If all classes in the Java Virtual Machine (JVM) instance were loaded
at the start of an application, this rule would never be broken. However,
the JVM loads certain classes on demand, and some of the JVM classes
have the full privileges. Classes in
packages that are listed in the \texttt{package.access} property of
\texttt{java.security.Security} are not subject to this rule because they are intended to be
loaded when accessed by a trusted proxy class. 

\subsection{Security Manager Rule}

The \textit{Security Manager rule} states that the manager cannot
be changed if a \emph{self-protecting} security manager has been set
by the application. This rule is violated when code causes a change
in the sandbox's configuration, the goal of many exploits. This rule
is an implementation of the strong mitigation.

\section{Validating the Rules}\label{sec:Mitigations}

In Section \ref{sec:Security-Manager-Study}, we discussed four hypotheses about security manager usage in benign applications, each
of which, if validated, leads to a distinct mitigation. In Section
\ref{sec:Study-results}, we gave empirical evidence in support of
Hypothesis 3 and rejected all of the others. Along the way, we learned
practical lessons about how applications use the Java sandbox that
are useful to exploit mitigation implementers. 

In this section, we evaluate the protection merits and backwards-compatibility of the rules presented in Section \ref{sec:Rules-for-Fortifying} through an implementation of runtime monitors that enforce them. This evaluation was done in collaboration
with a large aerospace company.

Section \ref{sub:Implementation-Using-JVMTI} discusses how we implemented
our runtime monitors using JVMTI. Section \ref{sub:Effectiveness-at-Fortifying}
explains the methodology behind and results of an experiment we conducted
to determine how effective the rules are at stopping existing exploits without breaking benign applications. Finally, Section
\ref{sub:Related-Work-Mitigation} covers prior work related to Java exploit mitigations.

\subsection{Implementation Using JVMTI}\label{sub:Implementation-Using-JVMTI}

JVMTI is a native interface used to create
analysis tools such as profilers, debuggers, monitors, and thread
analyzers. Tools that use JVMTI are called agents, and are attached
to a running Java application at a configuration-specific point in
the application's lifecycle. The interface allows an agent to set
capabilities, enabling the tool to intercept events such as class
or thread creation, field access or modification, breakpoints, etc.

Our agent \footnote{Our agent is open source. An anonymized version
of the tool can be found at http://goo.gl/In6Di0} must intercept three events to enforce the Privilege Escalation
and Security Manager rules: \texttt{ClassPrepare}, \texttt{FieldAccess},
and \texttt{FieldModification}. Enforcement of these rules is discussed in subsections \ref{sub:Enforcing-the-Privilege} and \ref{sub:Enforcing-the-SecurityManager}.

The field events require JVMTI to turn off the JIT, which slows down program
execution enough that our monitors are not suitable for adoption on their
own. JVMTI implementations can avoid this limitation, but avoidance would likely
increase implementation complexity beyond what is reasonable for a diagnostic
interface. We are currently in communication with the OpenJDK developers on
their security-dev mailing list regarding enforcement of our rules in the JVM
itself to avoid overhead issues.
\todo{Note: I moved the next sentence from the intro, which was too long. It may
not belong here and definitely needs to be integrated into the surrounding text.}
 This implementation strategy is motivated by
two concerns: Existing mechanisms for monitoring the execution of Java
applications are either (1) insufficient to securely enforce the rules
(e.g. bytecode instrumentation) or, like JVMTI, (2) unacceptably degrade
performance by disabling the just-in-time compiler (JIT). 
\footnote{REVIEWERS: This discussion will be referenced in the final version of the paper. At this time, the OpenJDK developers are very receptive to the idea, were already considering implementing something similar to our SecurityManager rule, and have stated the lessons from the empirical study we shared with in an early manuscript of this paper are valuable to their efforts.}

\subsubsection{Enforcing the Privilege Escalation Rule}\label{sub:Enforcing-the-Privilege}

The Privilege Escalation rule is enforced by ensuring that classes
can only load or cause the loading of more privileged classes in restricted-access
packages after a self-protecting security manager has been set. \textit{Restricted-access
packages} are packages that are public but not intended to be directly
used by typical Java applications; they are meant for internal JRE
use only. These packages are listed in the \texttt{package.access}
property in the \texttt{java.security.Security} class. There are two
ways to unsafely and directly access packages listed in this property:
(1) exploit a vulnerability in a class that can access them or (2)
allow access via the \texttt{accessClassInPackage} permission.

Applications use JRE classes which call restricted access package
classes. Thus, we must allow JRE to load restricted-access packages
at runtime. For example, many of the classes in the \texttt{java.lang.reflect}
package are backed by classes in the \texttt{sun} package, which is
a restricted-access package containing the internal implementations
for many Java features. However, enforcing the Privilege Escalation
rule prevents exploits from elevating the privileges of their payloads
because the payloads can not be in restricted-access packages with
default JRE configurations. 

To enforce the Privilege Escalation rule, our agent registers for
the \texttt{ClassPrepare} event, which allows the agent to inspect
a class after it is fully loaded but just before any of its code is
executed. Assuming the loaded class is not in a restricted-access
package, the agent inspects the stack frame to determine which class
caused the new class to be loaded. The agent must then get the protection
domains for both classes to ensure the loaded class is not more privileged.

\subsubsection{Enforcing the SecurityManager Rule}\label{sub:Enforcing-the-SecurityManager}

The SecurityManager rule is enforced by monitoring every read from
and write to the \texttt{security} field of the \texttt{System} class:
This field stores the security manager that is used by protected code.
The agent implements the read and write monitors by respectively registering
\texttt{FieldAccess and FieldModification} events for the field. Typically
the field is accessed via \texttt{System.getSecurityManager()}
and modified using \texttt{System.setSecurityManager()}, but we must
monitor the field instead of instrumenting these methods to detect
type confusion attacks. 

The agent stores a shadow copy of the application's most recent security
manager to have a trusted copy of the manager that can be used to
check for rule violations. This copy is only
updated by the modification event, which receives the new manager
as a parameter from JVMTI whenever the event is triggered.

Modification events are used to detect any change to a self-protecting
security manager. When the field is written, the agent checks the
shadow copy of the manager. Assuming the shadow copy is \texttt{null},
the agent knows the manager is being set for the first time and checks
to see if the new manager is self-protecting. If the manager is self-protecting
the agent simply updates the shadow copy. Otherwise the agent stops monitoring the application because the rule does not apply in the presence of a defenseless manager. Any further changes to the self-protecting manager are logged.

Access events are used to detect type confusion attacks against the
manager. The modification event we register will not be triggered
when the manager is changed due to a type confusion attack. When a
type confusion attack is used to masquerade a malicious class as the
\texttt{System} class, the malicious copy will have different internal
JVM identifiers for the class itself and its methods. Even given these
differences, updating a field in one version of the class updates
the value the JVM stores for the field in both classes because \texttt{System} is static and both classes appear to have the same type. The
modification and access events are registered for specific field and
class identifiers, thus the events are not triggered for operations
on the malicious version. We leverage the mismatch this causes between
the set security manager and our shadow copy by checking to see if
the manager that is read in the access event has the same internal
JVM reference as our shadow copy. When the two references do not match,
the manager has been changed by a malicious class masquerading as
\texttt{System}. Type confusion attacks may also be used to masquerade
a class as a privileged class loader to elevate the privileges of
a payload class that disables the manager; this scenario is detected
by the modification event.


\subsection{Effectiveness at Fortifying the Sandbox}\label{sub:Effectiveness-at-Fortifying}

%%Need to integrate backwards-compatibility experiment here and mention proprietary applications tested through aerospace collaborator.

We performed an experiment to evaluate how effective our rules are
at blocking exploits that disable the sandbox. In our experiment,
we ran Java 7 exploits for the browser from Metasploit 4.10.0 on 64-bit
Windows 7 against the initial release of version 7 of the JRE. This
version of Metasploit contains twelve applets that are intended to
exploit JRE 7 or earlier, but two did not successfully run due to
Java exceptions we did not debug. Metasploit contains many Java exploits
outside of the subset we used, but the excluded exploits either only
work against long obsolete versions of the JRE or are not well positioned
to be used in drive-by downloads. 

We ran the ten exploits in our set under the following conditions:
(1) without the agent, (2) with the agent but only enforcing the Privilege
Escalation rule, and (3) while enforcing both rules. We tested the Privilege Escalation rule separately from the Security Manager rule because the latter stops all of the exploits on its own. All
ten of the exploits succeed against our JRE without the agent. Four
were stopped by the Privilege Escalation rule. All ten were stopped
when both rules were enforced. The exploits that were not stopped
by the Privilege Escalation rule were either type confusion exploits
or exploits that did not need to elevate the privileges of the payload
class. The payload class does not need elevated privileges when it
can directly access a privileged class to exploit. Table \ref{tab:Exploit-experiment-summary}
summarizes our results using the specific CVEs each exploit targeted.

\begin{table}
\protect\caption{Effectiveness test results.}\label{tab:Exploit-experiment-summary}


\centering{}%
\begin{tabular}{l>{\raggedright}p{3cm}l}
\toprule 
\textbf{CVE-ID} & \textbf{Privilege Escalation Monitor} & \textbf{Both Monitors}\tabularnewline
\midrule
2011-3544 & Attack Succeeded  & Attack Blocked\tabularnewline
2012-0507 & Attack Blocked & Attack Blocked\tabularnewline
2012-4681 & Attack Succeeded  & Attack Blocked\tabularnewline
2012-5076 & Attack Succeeded  & Attack Blocked\tabularnewline
2013-0422 & Attack Blocked & Attack Blocked\tabularnewline
2013-0431 & Attack Blocked & Attack Blocked\tabularnewline
2013-1488 & Attack Succeeded  & Attack Blocked\tabularnewline
2013-2423 & Attack Succeeded  & Attack Blocked\tabularnewline
2013-2460 & Attack Blocked & Attack Blocked\tabularnewline
2013-2465 & Attack Succeeded  & Attack Blocked\tabularnewline
\bottomrule
\end{tabular}
\end{table}

\subsection{Limitations}

Neither of these rules will stop all Java exploits. While the rules
catch all of the exploits in our set, some Java vulnerabilities can
be exploited to cause significant damage without disabling the security
manager. For example, our rules will not detect type confusion exploits
that mimic privileged classes to perform their operations directly.
However, our rules substantially improve Java sandbox security, and
future work will be able to build upon these results to create mitigation
techniques for additional types of exploits.


\section{Threats to Validity}

\subsection{Study limitations}\label{sub:Limitations-Study}
\subsubsection{Internal Validity}

Our results are dependent on accurately studying the source code of
applications and their comments. In most cases, security manager interactions
are easily understood, but there are a few particularly complex interactions
that may be misdiagnosed. Furthermore, we did not review all application
code, thus we may have taken a comment or some source code out of
context in larger applications. Finally, using two different reviewers
may lead to variations in the interpretations of some of the data. 

We mitigated these threats by using a checklist, FindBugs plugin, and JVMTI agent to
provide reviewers consistent processes for reviewing code
and validating their results. Furthermore,
we inspected entire source files that contained
security manager operations. We tested our tools and processes in a pilot study
to find and mitigate sources of inconsistencies.

\subsubsection{External Validity}

The study only includes open source applications. It is possible
that closed source applications interact with the security manager
in ways that we did not see in the open source community. However,
we inspected a few small applications with our aerospace collaborators.
We did not find any code that suggested this is the case. 

\subsubsection{Reliability}

While the majority of the study is easily replicable, GitHub search results are constantly
changing. Using GitHub to generate a new dataset using our method
would likely generate a different dataset. Furthermore, over the course of our security
manager study, two applications either became private repositories
or were removed from GitHub (FileManagerFtpHttpServer and Visor).

\section{Related work}
\label{sec:related}
% CLG: I know you guys like to put the related work inline, but it's just taking
% soooooo long to get to the actual meat of the paper.  Can we try it like this
% to see if it works?  I'll concede if you insist. 

\subsection{Study}

Several recent studies have examined the use of security libraries
and discovered rampant library misuse, which caused severe vulnerabilities.
Georgiev et al. uncovered vulnerabilities in dozens of security critical
applications caused by SSL library protocol violations \cite{georgiev12most-dangerous}.
These applications misconfigured high-level libraries such that the
high-level libraries misused low-level SSL libraries which in turn
failed silently. Somorovsky et al. demonstrate vulnerabilities in
11 security frameworks such that Security Assertion Markup Language
(SAML) assertions are not checked properly when certain API mis-orderings
are triggered \cite{somorovsky12breaking}. Li et al. examined browser-based
password managers and found that many of their features relied on
an incorrect version of the same-origin policy, which could allow
attackers to steal user credentials \cite{li2014emperor}. As far
as we are aware no study has examined Java applications' use of the
sandbox. Li Gong, the main designer of the Java security architecture,
admitted in a ten year retrospective on Java Security that he didn't
know how or how extensively the ``fine grained access control mechanism''
(i.e. the Java sandbox) is used \cite{gong2009java}. We fill in that
gap. 

\subsection{Mitigation}\label{sub:Related-Work-Mitigation}

Our rules increase the security of the sandbox
by effectively removing unnecessary features. Prior work has taken a different
approach, instead focusing on re-implementing the Java sandbox or
adding to the sandbox to increase security. Cappos et al. created
a new sandbox structure. They implemented a security isolated kernel
to separate sandboxed applications from the main system \cite{cappos_retaining_2010}.
They validated this structure by translating past Java CVEs into exploits
for the new kernel. Provos et al. describe a method of separating
privileges to reduce privilege escalation \cite{Provos-PrivilegeEscalation}.
Their approach is partially implemented in the Java security model.
Li and Srisa-an extended the Java sandbox by providing extra protection
for JNI calls \cite{li_quarantine:_2011}. Their implementation, Quarantine,
separates JNI accessible objects to a heap which contains extra protection
mechanisms. The performance of their mechanism is also measured using
DaCapo. Siefers et al. created a tool, Robusta, which separates JNI
code into another sandbox \cite{siefers_robusta:_2010}%
\begin{comment}
Cite TISSEC journal version of Robusta paper
\end{comment}
. Sun and Tan extend the Robusta technique to be JVM independent \cite{sun_jvm-portable_2012}. 

Java applets are the most common ways to transmit Java exploits. Detectors
have been created to identify drive-by downloads in JavaScript \cite{cova_detection_2010},
and in Adobe Flash \cite{ford_analyzing_2009}. Helmer et al. used
machine learning to identify malicious applets \cite{helmer_anomalous_2001}.
Their approach monitored system call traces to identify malicious
behavior after execution. However, this approach is entirely reactive.
Our approach terminates exploits when they attempt to break out of
the sandbox, before the exploit performs its payload. Schlumberger
et al. used machine learning and static analysis to identify common
exploit features in malicious applets \cite{schlumberger_jarhead_2012}.
Blasing et al. used static analysis and dynamic analysis of sandboxed
executions to detect malicious Android applications \cite{Blasing-AndriodSandbox}.
Unlike these automated approaches, our rules shows that unique
mitigation strategies can be created with a better understanding of
how applications interact with the sandbox. 


\section{Conclusion}

\todo{CLG moved the following two paragraphs from what used to be section 3; my
  thought is we could have a longer ``discussion'' of Java software development
  and its relationship to security, and I think these two paragraphs might fit
  in well there.}
Many of the recent type confusion and privilege escalation vulnerabilities
would not have been introduced if the JRE were developed strictly
following ``The CERT Oracle Secure Coding Standard for Java'' \cite{long_cert_2011}.
For example, Svoboda \cite{svoboda_anatomy_blog_2013,svoboda_anatomy_2014}
pointed out that CVE-2012-0507 and CVE-2012-4681 were caused by violating
a total of six different secure coding rules and four guidelines. 

In the typical case, following just one or two of the broken rules
and guidelines would have prevented a serious exploit. For example,
CVE-2012-4681 resulted from two rule violations in a privileged Abstract
Window Toolkit (AWT) class in the \texttt{sun} package and two rule
violations and an ignored guideline in a JavaBean class. The bean
class was exploited to access the AWT class. The AWT class contained
a method that reflectively fetched any field in any class, made the
field public, and returned it. This is a violation of rule SEC05-J
because reflection is being used to increase the accessibility of
fields. It is also a violation of SEC00-J because the AWT class is
privileged and leaks sensitive information (the fields) across trust
boundaries. The AWT class should have followed all of the secure coding
guidelines, but its violation of SEC00-J is especially problematic---the
exploits use the leaked fields to disable the security manager. 


Our study of Java sandbox usage in open-source applications found
that the majority of studied applications do not change the security
manager. Some of the remaining applications use the security manager
only for non-security purposes. The final set of applications use
the sandbox for security and either initialize a self-protecting security
manager and never modify it or set a defenseless manager and modify
it at run time. 

These findings, in combination with our analysis of recent Java exploits,
enabled us to define two rules which together successfully
defeated Metasploit's applet exploits without breaking backward compatibility with benign applications when enforced by an experimental JVMTI agent. Some of the studied applications
used the security manager to prevent third party components from calling
\texttt{System.exit()}. More generally, frameworks often need to enforce
constraints on plugins (e.g. to ensure non-interference). This suggests
that Java should provide a simpler, alternative mechanism for constraining
access to global resources. This is supported by our findings that
show developers attempting to make non-trivial use of the sandbox
often do so incorrectly. One intriguing possibility is to allow programmers
to strengthen the policy temporarily (e.g. by adding a permission). 

We indirectly observed many developers struggling to understand and
use the security manager for any purpose. This is perhaps why there
were only 46 applications in our sample. Some developers seemed to
misunderstand the interaction between policy files and the security
manager that enforces the policy. Other developers appear confused
about how permissions work. In particular, they do not realize that
restricting just one permission but allowing all others enables a
\emph{defenseless} sandbox. Our concerns are shared by the IntelliJ developers, who included static analysis checks to warn developers that a security expert should check their interactions with the security manager.\footnote{http://www.jetbrains.com/idea/documentation/inspections.jsp%
} In general, sandbox-defeating permissions
should be packaged and segregated to prevent accidental creation of
defenseless sandboxes. More generally, some developers appear to believe
the sandbox functions as a blacklist when, in reality, it is a whitelist.
These observations suggest that more resources---tool support, improved
documentation, or better error messages---should be dedicated to helping
developers correctly use the sandbox. 

\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}
